{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of chronos on aquifer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import joblib\n",
    "\n",
    "import time\n",
    "from datasetsforecast.m3 import M3\n",
    "from utilsforecast.losses import *\n",
    "from utilsforecast.evaluation import evaluate\n",
    "import torch\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "aquifer_by_stations = joblib.load('aquifer_by_stations.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the datetime\n",
    "for key, data in aquifer_by_stations.items():\n",
    "    data['date'] = pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try for only one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifer = aquifer_by_stations[85012]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_scaling(x):\n",
    "    mean = np.mean(np.abs(x))\n",
    "\n",
    "    return x/mean\n",
    "\n",
    "def standard_scaling(x):\n",
    "    mean = np.mean(np.abs(x))\n",
    "    s = np.std(x)\n",
    "\n",
    "    return (x - mean)/s\n",
    "\n",
    "def standard_unscaling(original, scaled):\n",
    "    mean = np.mean(np.abs(original))\n",
    "    s = np.std(original)\n",
    "\n",
    "    return (scaled * s) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = aquifer['altitude'].values\n",
    "y_scaled = mean_scaling(y)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=1, nrows=2)\n",
    "\n",
    "ax1.plot(aquifer['date'], y, color='blue', label='Original')\n",
    "ax1.set_ylabel('Daily visits')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(aquifer['date'], y_scaled, color='orange', label='Scaled')\n",
    "ax2.set_ylabel('Daily visits (scaled)')\n",
    "ax2.legend()\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs\n",
    "#%pip install -U git+https://github.com/amazon-science/chronos-forecasting.git\n",
    "#%pip install neuralforecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-large\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "horizon = 10\n",
    "history = 100\n",
    "\n",
    "\n",
    "chronos_tiny_preds = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "y = aquifer['altitude'].values\n",
    "y_scaled = standard_scaling(y)\n",
    "y = torch.tensor(y_scaled[-history:-horizon])\n",
    "\n",
    "forecast = pipeline.predict(\n",
    "    context= y,\n",
    "    prediction_length=horizon,\n",
    "    num_samples=20\n",
    ")\n",
    "\n",
    "low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "\n",
    "chronos_tiny_duration = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer['date'][-100:], y_scaled[-100:], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(aquifer['date'][-horizon:], median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(aquifer['date'][-horizon:], low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinusoid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "\n",
    "# 0 to 20pi range with 1000 points\n",
    "time_a = np.linspace(0 , 20 * np.pi, num_points)\n",
    "frequency = 1\n",
    "amplitude = 0.01  # Amplitude of the sine wave\n",
    "\n",
    "# Generate the sine wave data\n",
    "sinusoid = amplitude * np.sin(frequency * time_a)\n",
    "\n",
    "# Shift the curve up by 1\n",
    "shifted_sinusoid = sinusoid + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the shifted sinusoidal curve\n",
    "plt.plot(shifted_sinusoid, label='Shifted Sinusoid')\n",
    "plt.title('Shifted Sinusoidal Curve Around 1')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.axhline(y=1, color='r', linestyle='--', label='y=1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-tiny\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "horizon = 50\n",
    "history = 1000\n",
    "\n",
    "\n",
    "chronos_tiny_preds = []\n",
    "\n",
    "\n",
    "y = torch.tensor(shifted_sinusoid[:-horizon])\n",
    "\n",
    "forecast = pipeline.predict(\n",
    "    context= y,\n",
    "    prediction_length=horizon,\n",
    "    num_samples=20\n",
    ")\n",
    "\n",
    "low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_index = range(num_points - horizon, num_points)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(shifted_sinusoid, color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(forecast_index, low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinusoid data with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-tiny\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "horizon = 50\n",
    "history = 1000\n",
    "\n",
    "\n",
    "chronos_tiny_preds = []\n",
    "\n",
    "shifted_sinusoid_scaled = standard_scaling(shifted_sinusoid)\n",
    "y = torch.tensor(shifted_sinusoid_scaled[:-horizon])\n",
    "\n",
    "forecast = pipeline.predict(\n",
    "    context= y,\n",
    "    prediction_length=horizon,\n",
    "    num_samples=20\n",
    ")\n",
    "\n",
    "low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "# Unscale the forescasts\n",
    "low = standard_unscaling(shifted_sinusoid, low)\n",
    "median = standard_unscaling(shifted_sinusoid, median)\n",
    "high = standard_unscaling(shifted_sinusoid, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_index = range(num_points - horizon, num_points)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(shifted_sinusoid, color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(forecast_index, low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><sup>!!! From the sinusoid experiment we found out, that if the data is pretty constant (small deviations), we should use standard scaling on the data, before passing it to chronos. Otherwise most of the predictions can fall into the same bit.</sub></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinusoid data with scaling (longer prediction period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-tiny\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Parameters\n",
    "day_len = 100\n",
    "horizon = 5\n",
    "\n",
    "# List for storing the r2 scores\n",
    "r2_scores = [[] for _ in range(5)]\n",
    "\n",
    "\n",
    "# List for storing the predictions\n",
    "predictions = [[] for _ in range(5)]\n",
    "\n",
    "shifted_sinusoid_scaled = standard_scaling(shifted_sinusoid)\n",
    "y = torch.tensor(shifted_sinusoid_scaled[:-horizon])\n",
    "\n",
    "# Iterate from day_len days before the end, to the last day\n",
    "for i in range(day_len + (horizon-1), 0, -1):\n",
    "\n",
    "    y = torch.tensor(shifted_sinusoid_scaled[:-i])\n",
    "\n",
    "    \n",
    "\n",
    "    forecast = pipeline.predict(\n",
    "        context= y,\n",
    "        prediction_length=horizon,\n",
    "        num_samples=20\n",
    "    )\n",
    "\n",
    "    low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "    median = standard_unscaling(shifted_sinusoid, median)\n",
    "\n",
    "    # Store the results for every prediction horizon separately\n",
    "    for i in range(5):\n",
    "        predictions[i].append(median[i])\n",
    "\n",
    "# Clean up the results\n",
    "predictions[0] = predictions[0][-day_len:]\n",
    "predictions[1] = predictions[1][3:-1]\n",
    "predictions[2] = predictions[2][2:-2]\n",
    "predictions[3] = predictions[3][1:-3]\n",
    "predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "# Calculate the r2 scores and store them in a list\n",
    "for i in range(5):\n",
    "    r2_scores[i].append(r2_score(shifted_sinusoid[-day_len:], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_index = range(0, 50)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(forecast_index, shifted_sinusoid[-50:], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, predictions[0][-50:], color=\"orange\", label=\"median forecast\")\n",
    "plt.plot(forecast_index, predictions[4][-50:], color=\"tomato\", label=\"median forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset (from chronos github repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # requires: pip install pandas\n",
    "import torch\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"cuda\",  # use \"cpu\" for CPU inference and \"mps\" for Apple Silicon\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/AileenNielsen/TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\")\n",
    "\n",
    "# context must be either a 1D tensor, a list of 1D tensors,\n",
    "# or a left-padded 2D tensor with batch as the first dimension\n",
    "# forecast shape: [num_series, num_samples, prediction_length]\n",
    "forecast = pipeline.predict(\n",
    "    context=torch.tensor(df[\"#Passengers\"]),\n",
    "    prediction_length=12,\n",
    "    num_samples=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # requires: pip install matplotlib\n",
    "import numpy as np\n",
    "\n",
    "forecast_index = range(len(df), len(df) + 12)\n",
    "low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df[\"#Passengers\"], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index, median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(forecast_index, low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on aquifer data with relative differences in altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_aquifer = aquifer_by_stations[85012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-large\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "horizon = 3\n",
    "history = 100\n",
    "\n",
    "\n",
    "chronos_tiny_preds = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "y = relative_aquifer['altitude_diff'].values\n",
    "y_scaled = standard_scaling(y)\n",
    "#y_scaled = y\n",
    "y = torch.tensor(y_scaled[-history:-horizon])\n",
    "\n",
    "forecast = pipeline.predict(\n",
    "    context= y,\n",
    "    prediction_length=horizon,\n",
    "    num_samples=20\n",
    ")\n",
    "\n",
    "low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "\n",
    "chronos_tiny_duration = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(relative_aquifer['date'][-100:], y_scaled[-100:], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(relative_aquifer['date'][-horizon:], median, color=\"tomato\", label=\"median forecast\")\n",
    "plt.fill_between(relative_aquifer['date'][-horizon:], low, high, color=\"tomato\", alpha=0.3, label=\"80% prediction interval\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing multiple prediction horizons (without scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_aquifer = aquifer_by_stations[85065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-large\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "horizon = 5\n",
    "history = 100\n",
    "\n",
    "day_1 = []\n",
    "day_2 = []\n",
    "day_3 = []\n",
    "day_4 = []\n",
    "day_5 = []\n",
    "\n",
    "day_len = 200\n",
    "\n",
    "# Iterate from day_len days before the end, to the last day\n",
    "for i in range(day_len + 4, 0, -1):\n",
    "    y = relative_aquifer['altitude_diff'].values\n",
    "    y = torch.tensor(y[:-i])\n",
    "    \n",
    "    forecast = pipeline.predict(\n",
    "        context= y,\n",
    "        prediction_length=horizon,\n",
    "        num_samples=20\n",
    "    )\n",
    "    \n",
    "    low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "    # store the results\n",
    "    day_1.append(median[0])\n",
    "    day_2.append(median[1])\n",
    "    day_3.append(median[2])\n",
    "    day_4.append(median[3])\n",
    "    day_5.append(median[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the results\n",
    "day_1 = day_1[-200:]\n",
    "day_2 = day_2[3:-1]\n",
    "day_3 = day_3[2:-2]\n",
    "day_4 = day_4[1:-3]\n",
    "day_5 = day_5[0:-4]\n",
    "print(len(day_1))\n",
    "print(len(day_2))\n",
    "print(len(day_3))\n",
    "print(len(day_4))\n",
    "print(len(day_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise time series with predictions with one day ahead\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(relative_aquifer['date'][-1000:], y[-1000:], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(relative_aquifer['date'][-day_len:], day_1, color=\"tomato\", label=\"median forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise time series with predictions with one day ahead\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(relative_aquifer['date'][-1000:], y[-1000:], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(relative_aquifer['date'][-day_len:], day_2, color=\"tomato\", label=\"median forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise time series with predictions with one day ahead\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(relative_aquifer['date'][-1000:], y[-1000:], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(relative_aquifer['date'][-day_len:], day_3, color=\"tomato\", label=\"median forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise time series with predictions with one day ahead\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(relative_aquifer['date'][-1000:], y[-1000:], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(relative_aquifer['date'][-day_len:], day_4, color=\"tomato\", label=\"median forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise time series with predictions with one day ahead\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(relative_aquifer['date'][-1000:], y[-1000:], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(relative_aquifer['date'][-day_len:], day_5, color=\"tomato\", label=\"median forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_1_day = r2_score(relative_aquifer['altitude_diff'][-day_len:], day_1)\n",
    "r2_2_day = r2_score(relative_aquifer['altitude_diff'][-day_len:], day_2)\n",
    "r2_3_day = r2_score(relative_aquifer['altitude_diff'][-day_len:], day_3)\n",
    "r2_4_day = r2_score(relative_aquifer['altitude_diff'][-day_len:], day_4)\n",
    "r2_5_day = r2_score(relative_aquifer['altitude_diff'][-day_len:], day_5)\n",
    "\n",
    "print(f\"1 day ahead: {r2_1_day}\")\n",
    "print(f\"2 days ahead: {r2_2_day}\")\n",
    "print(f\"3 days ahead: {r2_3_day}\")\n",
    "print(f\"4 days ahead: {r2_4_day}\")\n",
    "print(f\"5 days ahead: {r2_5_day}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation for cumulative altitude (one day ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the predicted relative differences to the absolute altitudes\n",
    "\n",
    "# Get the last day_len + 1 days without the last one\n",
    "altitudes = relative_aquifer['altitude'][-(day_len+1):-1]\n",
    "\n",
    "# Sum original altitudes and relative differences\n",
    "altitudes = altitudes + day_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the r2 score\n",
    "r2_score(relative_aquifer['altitude'][-day_len:], altitudes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing multiple prediction horizons (with scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_aquifer = aquifer_by_stations[85065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-large\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "horizon = 5\n",
    "history = 100\n",
    "\n",
    "day_1 = []\n",
    "day_2 = []\n",
    "day_3 = []\n",
    "day_4 = []\n",
    "day_5 = []\n",
    "\n",
    "day_len = 200\n",
    "\n",
    "# Iterate from day_len days before the end, to the last day\n",
    "for i in range(day_len + 4, 0, -1):\n",
    "    y = relative_aquifer['altitude'].values\n",
    "    y_scaled = standard_scaling(y)\n",
    "    y = torch.tensor(y_scaled[:-i])\n",
    "    \n",
    "    forecast = pipeline.predict(\n",
    "        context= y,\n",
    "        prediction_length=horizon,\n",
    "        num_samples=20\n",
    "    )\n",
    "    \n",
    "    low, median, high = np.quantile(forecast[0].numpy(), [0.1, 0.5, 0.9], axis=0)\n",
    "\n",
    "    # Unscale the predictions\n",
    "    median = standard_unscaling(relative_aquifer['altitude'], median)\n",
    "\n",
    "    #store the results\n",
    "    day_1.append(median[0])\n",
    "    day_2.append(median[1])\n",
    "    day_3.append(median[2])\n",
    "    day_4.append(median[3])\n",
    "    day_5.append(median[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the results\n",
    "day_1 = day_1[-200:]\n",
    "day_2 = day_2[3:-1]\n",
    "day_3 = day_3[2:-2]\n",
    "day_4 = day_4[1:-3]\n",
    "day_5 = day_5[0:-4]\n",
    "print(len(day_1))\n",
    "print(len(day_2))\n",
    "print(len(day_3))\n",
    "print(len(day_4))\n",
    "print(len(day_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise time series with predictions with one day ahead\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(relative_aquifer['date'][-1000:], relative_aquifer['altitude'][-1000:], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(relative_aquifer['date'][-day_len:], day_1, color=\"tomato\", label=\"median forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_1_day = r2_score(relative_aquifer['altitude'][-day_len:], day_1)\n",
    "r2_2_day = r2_score(relative_aquifer['altitude'][-day_len:], day_2)\n",
    "r2_3_day = r2_score(relative_aquifer['altitude'][-day_len:], day_3)\n",
    "r2_4_day = r2_score(relative_aquifer['altitude'][-day_len:], day_4)\n",
    "r2_5_day = r2_score(relative_aquifer['altitude'][-day_len:], day_5)\n",
    "\n",
    "print(f\"1 day ahead: {r2_1_day}\")\n",
    "print(f\"2 days ahead: {r2_2_day}\")\n",
    "print(f\"3 days ahead: {r2_3_day}\")\n",
    "print(f\"4 days ahead: {r2_4_day}\")\n",
    "print(f\"5 days ahead: {r2_5_day}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging results for multiple aquifer stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last 5 days\n",
    "# This is done to enable direct comparison to the randomforest,\n",
    "# there the 5 days are removed because of the weather forecast generation\n",
    "for aquifer in aquifers_list:\n",
    "    aquifer_by_stations[aquifer] = aquifer_by_stations[aquifer][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-large\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "horizon = 5\n",
    "day_len = 365\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(5)]\n",
    "\n",
    "# Create a dictionary for the predictions from all of the different aquifers\n",
    "predictions_by_stations = {key: [] for key in aquifers_list}\n",
    "\n",
    "for aquifer in aquifers_list:\n",
    "    # List for storing the predictions\n",
    "    predictions = [[] for _ in range(5)]\n",
    "\n",
    "\n",
    "    # Iterate from day_len days before the end, to the last day\n",
    "    for i in range(day_len + (horizon-1), 0, -1):\n",
    "        \n",
    "        y = aquifer_by_stations[aquifer]['altitude_diff'].values\n",
    "        y = torch.tensor(y[:-i])\n",
    "\n",
    "        forecast = pipeline.predict(\n",
    "            context= y,\n",
    "            prediction_length=horizon\n",
    "        )\n",
    "\n",
    "        median = np.quantile(forecast[0].numpy(), 0.5, axis=0)\n",
    "\n",
    "        # Store the results for every prediction horizon separately\n",
    "        for i in range(5):\n",
    "            predictions[i].append(median[i])\n",
    "    \n",
    "    # Clean up the results\n",
    "    predictions[0] = predictions[0][-day_len:]\n",
    "    predictions[1] = predictions[1][3:-1]\n",
    "    predictions[2] = predictions[2][2:-2]\n",
    "    predictions[3] = predictions[3][1:-3]\n",
    "    predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "    # Add the predictios to the dictionary\n",
    "    predictions_by_stations[aquifer] = predictions\n",
    "\n",
    "    # Calculate the r2 scores and store them in a list\n",
    "    for i in range(5):\n",
    "        r2_scores[i].append(r2_score(aquifer_by_stations[aquifer]['altitude_diff'][-day_len:], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise time series with predictions with one day ahead\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-50:], aquifer_by_stations[aquifer]['altitude_diff'][-50:], color=\"royalblue\", label=\"historical data\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-50:], predictions[0][-50:], color=\"tomato\", label=\"median forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-50:], predictions[1][-50:], color=\"green\", label=\"median forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-50:], predictions[2][-50:], color=\"orange\", label=\"median forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-50:], predictions_by_stations[85065][0][-50:], color=\"orange\", label=\"median forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/chronos-large/chronos-large-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/chronos-large/chronos-large-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/chronos-large/chronos-large-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary with predictions\n",
    "joblib.dump(predictions_by_stations, '../reports/chronos-large/chronos-large-ground-water-predictions.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
