{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing various statistical models** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sklearn-genetic-opt\n",
    "#%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "\n",
    "# RandomForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# GAFeatureSelectionCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn_genetic import GAFeatureSelectionCV\n",
    "from sklearn_genetic.plots import plot_fitness_evolution\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaling(x):\n",
    "    mean = np.mean(np.abs(x))\n",
    "    s = np.std(x)\n",
    "\n",
    "    return (x - mean)/s\n",
    "\n",
    "def standard_unscaling(original, scaled):\n",
    "    mean = np.mean(np.abs(original))\n",
    "    s = np.std(original)\n",
    "\n",
    "    return (scaled * s) + mean\n",
    "\n",
    "# Scaler, that scales data according to other data\n",
    "def standard_scaling_transform(original, to_scale):\n",
    "    mean = np.mean(np.abs(original))\n",
    "    s = np.std(original)\n",
    "\n",
    "    return (to_scale - mean)/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1** Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.1** Ground water data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "aquifer_by_stations = joblib.load('../data/interim/ground-water-and-weather.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters, that we want to keep in the data\n",
    "features_target = ['altitude_diff']\n",
    "features_train = ['year', 'month', 'day','altitude_diff_shift1', 'altitude_diff_shift2', 'altitude_diff_shift3', 'altitude_diff_shift4', 'altitude_diff_shift5', 'precipitation_average4', 'precipitation_average3', 'precipitation_average5', 'precipitation_average6', 'precipitation_average7', 'precipitation_shift1_average2', 'precipitation_shift1_average3', 'precipitation_average2', 'precipitation_shift1_average4', 'precipitation_average8', 'precipitation_shift1_average5', 'precipitation_average9', 'precipitation_shift1', 'precipitation_average10', 'precipitation_shift1_average6', 'precipitation_shift1_average7', 'precipitation_shift1_average8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date column to year, month and day columns\n",
    "for key in aquifer_by_stations.keys():\n",
    "    aquifer_by_stations[key]['year'] = aquifer_by_stations[key]['date'].dt.year\n",
    "    aquifer_by_stations[key]['month'] = aquifer_by_stations[key]['date'].dt.month\n",
    "    aquifer_by_stations[key]['day'] = aquifer_by_stations[key]['date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "aquifer_by_stations = joblib.load('../data/interim/ground-water-and-weather.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifer = 85065\n",
    "day_len = 365\n",
    "val_len = 100 # Length of validation set\n",
    "horizon = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = aquifer_by_stations[aquifer][:-(day_len + horizon + val_len)].drop(columns=['altitude_diff', 'altitude', 'date'])\n",
    "y_train = aquifer_by_stations[aquifer][features_target][horizon:-(day_len + val_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions\n",
    "postfixes = ['avg', 'min', 'max']\n",
    "for i in range(1,6):\n",
    "    for postfix in postfixes:\n",
    "        X_train[f\"precipitation_probability_{postfix}_shift-{i}\"] = X_train[f'precipitation_probability_{postfix}'].shift(-i)\n",
    "        X_train[f\"precipitation_intensity_{postfix}_shift-{i}\"] = X_train[f'precipitation_intensity_{postfix}'].shift(-i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last 5 values\n",
    "X_train = X_train[:-5]\n",
    "y_train = y_train[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import BaseCrossValidator\n",
    "\n",
    "class Last365TimeSeriesSplit(BaseCrossValidator):\n",
    "    def __init__(self, n_splits=1, test_size=365):\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        indices = np.arange(n_samples)\n",
    "        test_start = n_samples - self.test_size\n",
    "        train_indices = indices[:test_start]\n",
    "        test_indices = indices[test_start:]\n",
    "        yield train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series split\n",
    "#tscv = TimeSeriesSplit(n_splits=2)\n",
    "\n",
    "# Initialize model\n",
    "model = GradientBoostingRegressor(n_estimators=50)\n",
    "\n",
    "# Initialize genetic algorithm feature selector with max_features set\n",
    "gafs = GAFeatureSelectionCV(\n",
    "    estimator=model,\n",
    "    cv=Last365TimeSeriesSplit(),\n",
    "    scoring=\"r2\",\n",
    "    population_size=200,\n",
    "    generations=25,\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    "    keep_top_k=5,\n",
    "    elitism=True,\n",
    "    max_features=40,  # Set the maximum number of features to select\n",
    "    mutation_probability=0.2,\n",
    "    crossover_probability=0.8\n",
    ")\n",
    "\n",
    "# Fit the feature selector\n",
    "gafs.fit(X_train, y_train)\n",
    "\n",
    "# Plot fitness evolution\n",
    "plot_fitness_evolution(gafs)\n",
    "# Output best features found\n",
    "print(\"Best Features Found:\", gafs.best_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafs.best_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best features to a list\n",
    "best_features = [item for item, keep in zip(X_train.columns, gafs.best_features_) if keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best features with 365 days validation\n",
    "'''\n",
    "Linear regression\n",
    "['cloud_cover_min_shift5',\n",
    " 'precipitation_intensity_avg_shift3',\n",
    " 'precipitation_intensity_max_shift2',\n",
    " 'temperature_avg_average6',\n",
    " 'cloud_cover_max_average7',\n",
    " 'humidity_min_average4',\n",
    " 'precipitation_probability_avg_average4',\n",
    " 'precipitation_probability_max_average2',\n",
    " 'precipitation_intensity_avg_average2',\n",
    " 'altitude_diff_shift2_average3',\n",
    " 'altitude_diff_shift5_average10',\n",
    " 'altitude_diff_shift7_average2',\n",
    " 'altitude_diff_shift9_average6',\n",
    " 'altitude_diff_shift10_average4',\n",
    " 'precipitation_shift10_average4',\n",
    " 'temperature_min_shift8_average3',\n",
    " 'temperature_min_shift9_average4',\n",
    " 'temperature_max_shift2_average7',\n",
    " 'temperature_max_shift3_average2',\n",
    " 'cloud_cover_min_shift10_average2',\n",
    " 'cloud_cover_max_shift3_average7',\n",
    " 'humidity_avg_shift1_average3',\n",
    " 'humidity_avg_shift2_average6',\n",
    " 'humidity_avg_shift6_average10',\n",
    " 'humidity_min_shift9_average3',\n",
    " 'humidity_max_shift6_average7',\n",
    " 'humidity_max_shift8_average5',\n",
    " 'precipitation_probability_avg_shift8_average7',\n",
    " 'precipitation_probability_min_shift1_average7',\n",
    " 'precipitation_probability_min_shift4_average9',\n",
    " 'precipitation_probability_max_shift1_average3',\n",
    " 'precipitation_probability_max_shift2_average7',\n",
    " 'precipitation_probability_max_shift7_average5',\n",
    " 'precipitation_probability_max_shift10_average2',\n",
    " 'precipitation_intensity_min_shift9_average6',\n",
    " 'precipitation_intensity_avg_shift-1',\n",
    " 'precipitation_probability_max_shift-1',\n",
    " 'precipitation_intensity_max_shift-1',\n",
    " 'precipitation_intensity_avg_shift-2']\n",
    " \n",
    " random forest\n",
    " ['precipitation_intensity_avg',\n",
    " 'temperature_max_shift5',\n",
    " 'cloud_cover_max_shift2',\n",
    " 'humidity_avg_shift1',\n",
    " 'precipitation_probability_min_shift7',\n",
    " 'altitude_diff_average3',\n",
    " 'temperature_max_average7',\n",
    " 'cloud_cover_min_average2',\n",
    " 'altitude_diff_shift6_average10',\n",
    " 'precipitation_shift2_average5',\n",
    " 'temperature_min_shift8_average2',\n",
    " 'temperature_min_shift9_average3',\n",
    " 'temperature_min_shift10_average9',\n",
    " 'temperature_max_shift2_average3',\n",
    " 'temperature_max_shift4_average9',\n",
    " 'cloud_cover_avg_shift2_average6',\n",
    " 'cloud_cover_avg_shift9_average6',\n",
    " 'cloud_cover_avg_shift10_average10',\n",
    " 'humidity_avg_shift3_average5',\n",
    " 'humidity_avg_shift5_average9',\n",
    " 'humidity_avg_shift8_average3',\n",
    " 'humidity_max_shift4_average2',\n",
    " 'humidity_max_shift6_average7',\n",
    " 'precipitation_intensity_avg_shift6_average3',\n",
    " 'precipitation_intensity_avg_shift8_average2',\n",
    " 'precipitation_intensity_avg_shift-1',\n",
    " 'precipitation_intensity_avg_shift-2']\n",
    " \n",
    " gradient boosting\n",
    " ['temperature_min',\n",
    " 'snow_accumulation_average6',\n",
    " 'temperature_avg_average2',\n",
    " 'cloud_cover_max_average3',\n",
    " 'humidity_avg_average4',\n",
    " 'precipitation_probability_avg_average2',\n",
    " 'precipitation_probability_max_average5',\n",
    " 'precipitation_intensity_avg_average6',\n",
    " 'snow_accumulation_shift1_average4',\n",
    " 'temperature_min_shift1_average3',\n",
    " 'temperature_min_shift3_average6',\n",
    " 'temperature_min_shift9_average5',\n",
    " 'temperature_max_shift4_average2',\n",
    " 'temperature_max_shift6_average6',\n",
    " 'humidity_avg_shift10_average2',\n",
    " 'humidity_min_shift8_average2',\n",
    " 'humidity_min_shift9_average8',\n",
    " 'humidity_min_shift10_average5',\n",
    " 'humidity_max_shift3_average10',\n",
    " 'humidity_max_shift8_average8',\n",
    " 'humidity_max_shift8_average9',\n",
    " 'precipitation_probability_min_shift7_average4',\n",
    " 'precipitation_probability_min_shift9_average10',\n",
    " 'precipitation_probability_max_shift5_average10',\n",
    " 'precipitation_probability_max_shift10_average3',\n",
    " 'precipitation_intensity_avg_shift2_average2',\n",
    " 'precipitation_intensity_min_shift5_average4',\n",
    " 'precipitation_intensity_max_shift2_average10',\n",
    " 'precipitation_intensity_max_shift4_average5',\n",
    " 'precipitation_probability_avg_shift-1',\n",
    " 'precipitation_probability_avg_shift-2',\n",
    " 'precipitation_probability_max_shift-2',\n",
    " 'precipitation_intensity_max_shift-3']\n",
    " \n",
    " gradient boosting n_estimators=50\n",
    " ['precipitation_average6',\n",
    " 'temperature_max_average3',\n",
    " 'humidity_min_average4',\n",
    " 'humidity_min_average7',\n",
    " 'precipitation_probability_avg_average3',\n",
    " 'precipitation_probability_avg_average7',\n",
    " 'precipitation_intensity_max_average2',\n",
    " 'altitude_diff_shift4_average8',\n",
    " 'temperature_max_shift7_average2',\n",
    " 'cloud_cover_avg_shift1_average10',\n",
    " 'cloud_cover_min_shift1_average4',\n",
    " 'cloud_cover_min_shift1_average8',\n",
    " 'cloud_cover_min_shift6_average4',\n",
    " 'cloud_cover_max_shift5_average10',\n",
    " 'cloud_cover_max_shift8_average5',\n",
    " 'humidity_avg_shift3_average2',\n",
    " 'humidity_avg_shift3_average9',\n",
    " 'humidity_avg_shift8_average10',\n",
    " 'humidity_avg_shift9_average7',\n",
    " 'humidity_min_shift1_average4',\n",
    " 'humidity_min_shift1_average6',\n",
    " 'humidity_min_shift6_average4',\n",
    " 'humidity_min_shift8_average5',\n",
    " 'humidity_max_shift2_average8',\n",
    " 'humidity_max_shift5_average4',\n",
    " 'humidity_max_shift6_average4',\n",
    " 'precipitation_probability_avg_shift9_average9',\n",
    " 'precipitation_probability_min_shift10_average4',\n",
    " 'precipitation_probability_max_shift10_average5',\n",
    " 'precipitation_intensity_avg_shift10_average8',\n",
    " 'precipitation_intensity_min_shift10_average8',\n",
    " 'precipitation_intensity_max_shift6_average6',\n",
    " 'precipitation_probability_avg_shift-1',\n",
    " 'precipitation_intensity_avg_shift-2']\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best features for only linear regression\n",
    "'''\n",
    " ['temperature_avg_shift7',\n",
    " 'humidity_max_shift6',\n",
    " 'altitude_diff_average2',\n",
    " 'precipitation_average2',\n",
    " 'temperature_min_average2',\n",
    " 'temperature_min_average4',\n",
    " 'cloud_cover_avg_average9',\n",
    " 'precipitation_intensity_avg_average2',\n",
    " 'precipitation_intensity_min_average5',\n",
    " 'altitude_diff_shift6_average8',\n",
    " 'precipitation_shift10_average9',\n",
    " 'temperature_min_shift3_average6',\n",
    " 'temperature_max_shift1_average10',\n",
    " 'temperature_max_shift5_average10',\n",
    " 'temperature_max_shift9_average5',\n",
    " 'cloud_cover_avg_shift5_average7',\n",
    " 'cloud_cover_avg_shift8_average4',\n",
    " 'humidity_min_shift3_average10',\n",
    " 'humidity_min_shift4_average3',\n",
    " 'humidity_min_shift5_average2',\n",
    " 'humidity_min_shift7_average6',\n",
    " 'humidity_min_shift9_average3',\n",
    " 'humidity_min_shift10_average5',\n",
    " 'humidity_max_shift5_average5',\n",
    " 'precipitation_intensity_avg_shift1_average6',\n",
    " 'precipitation_intensity_avg_shift2_average3',\n",
    " 'precipitation_intensity_avg_shift2_average5',\n",
    " 'precipitation_intensity_avg_shift3_average9',\n",
    " 'precipitation_intensity_max_shift1_average8',\n",
    " 'precipitation_intensity_avg_shift-1',\n",
    " 'precipitation_intensity_max_shift-1',\n",
    " 'precipitation_probability_avg_shift-2',\n",
    " 'precipitation_probability_max_shift-2',\n",
    " 'precipitation_intensity_max_shift-2']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafs.get_feature_names_out(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['precipitation_intensity_avg',\n",
    " 'altitude_diff_shift3',\n",
    " 'altitude_diff_average2',\n",
    " 'precipitation_average2',\n",
    " 'precipitation_intensity_avg_average2',\n",
    " 'precipitation_shift1_average3',\n",
    " 'precipitation_shift3_average5',\n",
    " 'snow_accumulation_shift3_average6',\n",
    " 'temperature_avg_shift6_average2',\n",
    " 'temperature_avg_shift9_average9',\n",
    " 'temperature_min_shift3_average3',\n",
    " 'temperature_min_shift7_average6',\n",
    " 'temperature_min_shift10_average3',\n",
    " 'temperature_max_shift7_average2',\n",
    " 'cloud_cover_avg_shift3_average5',\n",
    " 'cloud_cover_avg_shift5_average9',\n",
    " 'cloud_cover_max_shift10_average8',\n",
    " 'humidity_avg_shift7_average2',\n",
    " 'humidity_min_shift1_average10',\n",
    " 'humidity_min_shift2_average10',\n",
    " 'humidity_min_shift6_average3',\n",
    " 'humidity_max_shift5_average9',\n",
    " 'precipitation_intensity_min_shift6_average10',\n",
    " 'precipitation_intensity_min_shift9_average4',\n",
    " 'precipitation_intensity_min_shift10_average10',\n",
    " 'precipitation_intensity_max_shift3_average5',\n",
    " 'precipitation_intensity_avg_shift-1',\n",
    " 'precipitation_intensity_avg_shift-2',\n",
    " # manually added features\n",
    " 'precipitation_intensity_avg_shift-3',\n",
    " 'precipitation_intensity_avg_shift-4',\n",
    " 'precipitation_intensity_avg_shift-5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best features with larger validation\n",
    "best_features = ['precipitation_intensity_avg',\n",
    " 'temperature_max_shift5',\n",
    " 'cloud_cover_max_shift2',\n",
    " 'humidity_avg_shift1',\n",
    " 'precipitation_probability_min_shift7',\n",
    " 'altitude_diff_average3',\n",
    " 'temperature_max_average7',\n",
    " 'cloud_cover_min_average2',\n",
    " 'altitude_diff_shift6_average10',\n",
    " 'precipitation_shift2_average5',\n",
    " 'temperature_min_shift8_average2',\n",
    " 'temperature_min_shift9_average3',\n",
    " 'temperature_min_shift10_average9',\n",
    " 'temperature_max_shift2_average3',\n",
    " 'temperature_max_shift4_average9',\n",
    " 'cloud_cover_avg_shift2_average6',\n",
    " 'cloud_cover_avg_shift9_average6',\n",
    " 'cloud_cover_avg_shift10_average10',\n",
    " 'humidity_avg_shift3_average5',\n",
    " 'humidity_avg_shift5_average9',\n",
    " 'humidity_avg_shift8_average3',\n",
    " 'humidity_max_shift4_average2',\n",
    " 'humidity_max_shift6_average7',\n",
    " 'precipitation_intensity_avg_shift6_average3',\n",
    " 'precipitation_intensity_avg_shift8_average2',\n",
    " 'precipitation_intensity_avg_shift-1',\n",
    " 'precipitation_intensity_avg_shift-2',\n",
    " #manually added\n",
    " 'precipitation_intensity_avg_shift-3',\n",
    " 'precipitation_intensity_avg_shift-4',\n",
    " 'precipitation_intensity_avg_shift-5',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions\n",
    "def weather_forecast(X_train):\n",
    "    postfixes = ['avg', 'min', 'max']\n",
    "    for i in range(1,6):\n",
    "        for postfix in postfixes:\n",
    "            X_train[f\"precipitation_probability_{postfix}_shift-{i}\"] = X_train[f'precipitation_probability_{postfix}'].shift(-i)\n",
    "            X_train[f\"precipitation_intensity_{postfix}_shift-{i}\"] = X_train[f'precipitation_intensity_{postfix}'].shift(-i)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aquifer in aquifers_list:\n",
    "    aquifer_by_stations[aquifer] = weather_forecast(aquifer_by_stations[aquifer])\n",
    "    aquifer_by_stations[aquifer] = aquifer_by_stations[aquifer][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon, day_len (number of predicted days), test_len (number of days used for final testing)\n",
    "horizon_max = 5\n",
    "day_len = 100\n",
    "test_len = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n",
    "    max_depth = trial.suggest_categorical('max_depth', [None, 10, 20, 30, 50])\n",
    "    max_features = trial.suggest_categorical('max_features', [\"sqrt\", \"log2\", 0.5, 1.0])\n",
    "\n",
    "    # Initialize the RandomForestClassifier\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  max_features=max_features,\n",
    "                                  n_jobs=6,\n",
    "                                  random_state=42)\n",
    "    \n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon_max)]\n",
    "    \n",
    "    for aquifer in aquifers_list:\n",
    "    \n",
    "        for horizon in range (1, horizon_max+1, 1):\n",
    "            # Define the train and test set\n",
    "            X_train = aquifer_by_stations[aquifer][best_features][:-(day_len + horizon + test_len)]\n",
    "            y_train = aquifer_by_stations[aquifer][features_target][horizon:-(day_len + test_len)]\n",
    "    \n",
    "            X_test = aquifer_by_stations[aquifer][best_features][-(day_len + horizon + test_len):-(horizon + test_len)]\n",
    "            y_test = aquifer_by_stations[aquifer][features_target][-(day_len + test_len):-test_len]\n",
    "    \n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "    \n",
    "            # Make predictions\n",
    "            forecast = model.predict(X_test).tolist()\n",
    "            \n",
    "            # Calculate and save the r2 score\n",
    "            r2_scores[horizon-1].append(r2_score(y_test, forecast))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "aquifer_by_stations = joblib.load('../data/interim/ground-water-and-weather.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters, that we want to keep in the data\n",
    "features_target = ['altitude_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date column to year, month and day columns\n",
    "for key in aquifer_by_stations.keys():\n",
    "    aquifer_by_stations[key]['year'] = aquifer_by_stations[key]['date'].dt.year\n",
    "    aquifer_by_stations[key]['month'] = aquifer_by_stations[key]['date'].dt.month\n",
    "    aquifer_by_stations[key]['day'] = aquifer_by_stations[key]['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best features with larger validation\n",
    "best_features = ['precipitation_intensity_avg',\n",
    " 'temperature_max_shift5',\n",
    " 'cloud_cover_max_shift2',\n",
    " 'humidity_avg_shift1',\n",
    " 'precipitation_probability_min_shift7',\n",
    " 'altitude_diff_average3',\n",
    " 'temperature_max_average7',\n",
    " 'cloud_cover_min_average2',\n",
    " 'altitude_diff_shift6_average10',\n",
    " 'precipitation_shift2_average5',\n",
    " 'temperature_min_shift8_average2',\n",
    " 'temperature_min_shift9_average3',\n",
    " 'temperature_min_shift10_average9',\n",
    " 'temperature_max_shift2_average3',\n",
    " 'temperature_max_shift4_average9',\n",
    " 'cloud_cover_avg_shift2_average6',\n",
    " 'cloud_cover_avg_shift9_average6',\n",
    " 'cloud_cover_avg_shift10_average10',\n",
    " 'humidity_avg_shift3_average5',\n",
    " 'humidity_avg_shift5_average9',\n",
    " 'humidity_avg_shift8_average3',\n",
    " 'humidity_max_shift4_average2',\n",
    " 'humidity_max_shift6_average7',\n",
    " 'precipitation_intensity_avg_shift6_average3',\n",
    " 'precipitation_intensity_avg_shift8_average2',\n",
    " 'precipitation_intensity_avg_shift-1',\n",
    " 'precipitation_intensity_avg_shift-2',\n",
    " #manually added\n",
    " 'precipitation_intensity_avg_shift-3',\n",
    " 'precipitation_intensity_avg_shift-4',\n",
    " 'precipitation_intensity_avg_shift-5',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions\n",
    "def weather_forecast(X_train):\n",
    "    postfixes = ['avg', 'min', 'max']\n",
    "    for i in range(1,6):\n",
    "        for postfix in postfixes:\n",
    "            X_train[f\"precipitation_probability_{postfix}_shift-{i}\"] = X_train[f'precipitation_probability_{postfix}'].shift(-i)\n",
    "            X_train[f\"precipitation_intensity_{postfix}_shift-{i}\"] = X_train[f'precipitation_intensity_{postfix}'].shift(-i)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aquifer in aquifers_list:\n",
    "    aquifer_by_stations[aquifer] = weather_forecast(aquifer_by_stations[aquifer])\n",
    "    aquifer_by_stations[aquifer] = aquifer_by_stations[aquifer][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''{'n_estimators': 164, 'max_depth': 20, 'max_features': 0.5}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "model = RandomForestRegressor(n_estimators= 164,\n",
    "                             max_depth=20,\n",
    "                             max_features=0.5,\n",
    "                             n_jobs=-1,\n",
    "                             random_state=42)\n",
    "\n",
    "horizon_max = 5\n",
    "day_len = 365\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon_max)]\n",
    "\n",
    "# Dictionary for storing the predictions for all of the stations\n",
    "predictions_by_stations = {key: [] for key in aquifers_list}\n",
    "\n",
    "for aquifer in aquifers_list:\n",
    "    predictions = []\n",
    "\n",
    "    for horizon in range (1, horizon_max+1, 1):\n",
    "        # Define the train and test set\n",
    "        X_train = aquifer_by_stations[aquifer][best_features][:-(day_len + horizon)]\n",
    "        y_train = aquifer_by_stations[aquifer][features_target][horizon:-day_len]\n",
    "\n",
    "        X_test = aquifer_by_stations[aquifer][best_features][-(day_len + horizon):-horizon]\n",
    "        y_test = aquifer_by_stations[aquifer][features_target][-day_len:]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = model.predict(X_test).tolist()\n",
    "\n",
    "        # Store to the predictions\n",
    "        predictions.append(forecast)\n",
    "        \n",
    "        # Calculate and save the r2 score\n",
    "        r2_scores[horizon-1].append(r2_score(y_test, forecast))\n",
    "\n",
    "    # Store the predictions to the dictionary\n",
    "    predictions_by_stations[aquifer] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['altitude_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[0][-200:], color=\"tomato\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[2][-200:], color=\"green\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[4][-200:], color=\"grey\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['precipitation_probability_max'][-200:].apply(lambda x: x/20), color=\"brown\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['precipitation'][-200:].apply(lambda x: x/130), color=\"olive\", label=\"forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions_by_stations[85064][0][-200:], color=\"grey\", label=\"forecast\")\n",
    "#plt.savefig('../data/interim/plot.svg', format='svg')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/randomforest/randomforest-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/randomforest/randomforest-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/randomforest/randomforest-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary with predictions\n",
    "joblib.dump(predictions_by_stations, '../reports/randomforest/randomforest-ground-water-predictions.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"font-size:1.5em;\">Testing shifts and averages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifer = aquifer_by_stations[85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer['date'][-60:-30], aquifer['altitude_diff'][-60:-30], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(aquifer['date'][-60:-30], aquifer['altitude_diff_shift1_average2'][-60:-30], color=\"tomato\", label=\"forecast\")\n",
    "plt.plot(aquifer['date'][-60:-30], aquifer['altitude_diff_shift2_average2'][-60:-30], color=\"green\", label=\"forecast\")\n",
    "plt.plot(aquifer['date'][-60:-30], aquifer['altitude_diff_shift3_average2'][-60:-30], color=\"orange\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"font-size:1.5em;\">Testing the weather data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer['date'][200:300], aquifer['altitude_diff'][200:300], color=\"royalblue\", label=\"true data\")\n",
    "#plt.plot(aquifer['date'][:60], aquifer['altitude_diff_shift1_average2'][:60], color=\"tomato\", label=\"forecast\")\n",
    "#plt.plot(aquifer['date'][:60], aquifer['altitude_diff_shift2_average2'][:60], color=\"green\", label=\"forecast\")\n",
    "#plt.plot(aquifer['date'][:60], aquifer['altitude_diff_shift3_average2'][:60], color=\"orange\", label=\"forecast\")\n",
    "plt.plot(aquifer['date'][200:300], aquifer['precipitation'][200:300].apply(lambda x: x/30), color=\"tomato\", label=\"true data\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"font-size:1.5em;\">Testing index shifts</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters, that we want to keep in the data\n",
    "features_target = ['altitude_diff']\n",
    "features_train = ['year', 'month', 'day','altitude_diff_shift1', 'altitude_diff_shift2', 'altitude_diff_shift3', 'altitude_diff_shift4', 'altitude_diff_shift5', 'precipitation_average4', 'precipitation_average3', 'precipitation_average5', 'precipitation_average6', 'precipitation_average7', 'precipitation_shift1_average2', 'precipitation_shift1_average3', 'precipitation_average2', 'precipitation_shift1_average4', 'precipitation_average8', 'precipitation_shift1_average5', 'precipitation_average9', 'precipitation_shift1', 'precipitation_average10', 'precipitation_shift1_average6', 'precipitation_shift1_average7', 'precipitation_shift1_average8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aquifer in aquifers_list:\n",
    "    aquifer_by_stations[aquifer]['day_shift'] = aquifer_by_stations[aquifer]['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "model = RandomForestRegressor(n_estimators= 51,\n",
    "                             criterion= 'squared_error',\n",
    "                             max_depth= 20,\n",
    "                             min_samples_split= 9,\n",
    "                             min_samples_leaf= 4,\n",
    "                             max_features= 0.36336466788790966,\n",
    "                             #bootstrap= True,\n",
    "                             oob_score= True,\n",
    "                             max_leaf_nodes= 10,\n",
    "                             min_impurity_decrease= 0.0,\n",
    "                             ccp_alpha= 0.0,\n",
    "                             #max_samples= None,\n",
    "                             n_jobs=6,\n",
    "                             random_state=42)\n",
    "\n",
    "horizon_max = 5\n",
    "day_len = 365\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon_max)]\n",
    "\n",
    "# List for storing the predictions (useful for visualization)\n",
    "predictions = []\n",
    "\n",
    "for aquifer in aquifers_list:\n",
    "    predictions = []\n",
    "\n",
    "    for horizon in range (1, horizon_max+1, 1):\n",
    "        # Define the train and test set\n",
    "        X_train = aquifer_by_stations[aquifer][features_train][:-(day_len + horizon)]\n",
    "        y_train = aquifer_by_stations[aquifer][features_target][horizon:-day_len]\n",
    "\n",
    "        X_test = aquifer_by_stations[aquifer][features_train][-(day_len + horizon):-horizon]\n",
    "        y_test = aquifer_by_stations[aquifer][features_target][-day_len:]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = model.predict(X_test).tolist()\n",
    "\n",
    "        # Store to the predictions\n",
    "        predictions.append(forecast)\n",
    "        \n",
    "        # Calculate and save the r2 score\n",
    "        r2_scores[horizon-1].append(r2_score(y_test, forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['altitude_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[0][-200:], color=\"tomato\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[1][-200:], color=\"green\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[2][-200:], color=\"orange\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"font-size:1.5em;\">Testing index shifts on sinusoid data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "\n",
    "# 0 to 20pi range with 1000 points\n",
    "time_a = np.linspace(0 , 20 * np.pi, num_points)\n",
    "frequency = 1\n",
    "amplitude = 0.01  # Amplitude of the sine wave\n",
    "\n",
    "# Generate the sine wave data\n",
    "sinusoid = amplitude * np.sin(frequency * time_a)\n",
    "\n",
    "# Shift the curve up by 1\n",
    "shifted_sinusoid = sinusoid + 1\n",
    "\n",
    "# cast to dataframe\n",
    "shifted_sinusoid = pd.DataFrame(shifted_sinusoid)\n",
    "\n",
    "shifted_sinusoid.rename(columns={0: 'absolute'}, inplace=True)\n",
    "\n",
    "shifted_sinusoid['diff'] = shifted_sinusoid['absolute'].diff()\n",
    "shifted_sinusoid['absolute_shift1'] = shifted_sinusoid['absolute'].shift(1)\n",
    "shifted_sinusoid['absolute_shift2'] = shifted_sinusoid['absolute'].shift(2)\n",
    "shifted_sinusoid['absolute_shift3'] = shifted_sinusoid['absolute'].shift(3)\n",
    "shifted_sinusoid['absolute_shift4'] = shifted_sinusoid['absolute'].shift(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_sinusoid = shifted_sinusoid[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_sinusoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the shifted sinusoidal curve\n",
    "plt.plot(shifted_sinusoid['absolute'][-50:], label='Shifted Sinusoid')\n",
    "plt.plot(shifted_sinusoid['absolute_shift1'][-50:], color='red', label='Shifted Sinusoid')\n",
    "plt.plot(shifted_sinusoid['absolute_shift2'][-50:], color='orange', label='Shifted Sinusoid')\n",
    "plt.title('Shifted Sinusoidal Curve Around 1')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.axhline(y=1, color='r', linestyle='--', label='y=1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "model = RandomForestRegressor(n_estimators= 1000,\n",
    "                             #criterion= 'squared_error',\n",
    "                             #max_depth= 20,\n",
    "                             #min_samples_split= 9,\n",
    "                             #min_samples_leaf= 4,\n",
    "                             #max_features= 0.36336466788790966,\n",
    "                             #bootstrap= True,\n",
    "                             #oob_score= True,\n",
    "                             #max_leaf_nodes= 10,\n",
    "                             #min_impurity_decrease= 0.0,\n",
    "                             #ccp_alpha= 0.0,\n",
    "                             #max_samples= None,\n",
    "                             n_jobs=6,\n",
    "                             random_state=42)\n",
    "\n",
    "horizon_max = 5\n",
    "day_len = 100\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon_max)]\n",
    "\n",
    "# List for storing the predictions (useful for visualization)\n",
    "predictions = []\n",
    "for horizon in range (1, horizon_max+1, 1):\n",
    "    # Define the train and test set\n",
    "    X_train = shifted_sinusoid[['diff', 'absolute_shift1', 'absolute_shift2',\n",
    "       'absolute_shift3', 'absolute_shift4' ]][:-(day_len + horizon)]\n",
    "    y_train = shifted_sinusoid['absolute'][horizon:-day_len]\n",
    "    X_test = shifted_sinusoid[['diff', 'absolute_shift1', 'absolute_shift2',\n",
    "       'absolute_shift3', 'absolute_shift4' ]][-(day_len + horizon):-horizon]\n",
    "    y_test = shifted_sinusoid['absolute'][-day_len:]\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make predictions\n",
    "    forecast = model.predict(X_test).tolist()\n",
    "    # Store to the predictions\n",
    "    predictions.append(forecast)\n",
    "    \n",
    "    # Calculate and save the r2 score\n",
    "    r2_scores[horizon-1].append(r2_score(y_test, forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(list(range(100)), shifted_sinusoid['absolute'][-100:], color=\"royalblue\", label=\"true data\")\n",
    "#plt.plot(predictions[0][-25:], color=\"red\", label=\"forecast\")\n",
    "#plt.plot(predictions[1][-25:], color=\"green\", label=\"forecast\")\n",
    "#plt.plot(predictions[2][-25:], color=\"purple\", label=\"forecast\")\n",
    "#plt.plot(predictions[3][-25:], color=\"orange\", label=\"forecast\")\n",
    "plt.plot(predictions[4][-100:], color=\"brown\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"font-size:1.5em;\">Testing with only one prediction horizon</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "model = RandomForestRegressor(n_estimators= 2000,\n",
    "                             #criterion= 'squared_error',\n",
    "                             #max_depth= 20,\n",
    "                             #min_samples_split= 9,\n",
    "                             #min_samples_leaf= 4,\n",
    "                             #max_features= 0.36336466788790966,\n",
    "                             #bootstrap= True,\n",
    "                             #oob_score= True,\n",
    "                             #max_leaf_nodes= 10,\n",
    "                             #min_impurity_decrease= 0.0,\n",
    "                             #ccp_alpha= 0.0,\n",
    "                             #max_samples= None,\n",
    "                             n_jobs=6,\n",
    "                             random_state=42)\n",
    "\n",
    "horizon = 5\n",
    "day_len = 200\n",
    "\n",
    "# List for storing the predictions (useful for visualization)\n",
    "predictions = []\n",
    "# Define the train and test set\n",
    "X_train = shifted_sinusoid[:-(day_len + horizon)]\n",
    "y_train = shifted_sinusoid[horizon:-day_len]\n",
    "X_test = shifted_sinusoid[-(day_len + horizon):-horizon]\n",
    "y_test = shifted_sinusoid[-day_len:]\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "forecast = model.predict(X_test).tolist()\n",
    "# Store to the predictions\n",
    "predictions.append(forecast)\n",
    "\n",
    "# Calculate and save the r2 score\n",
    "r2_scores[horizon-1].append(r2_score(y_test, forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(list(range(200)), shifted_sinusoid[-200:], color=\"royalblue\", label=\"true data\")\n",
    "#plt.plot(predictions[0][-25:], color=\"red\", label=\"forecast\")\n",
    "#plt.plot(predictions[1][-25:], color=\"green\", label=\"forecast\")\n",
    "#plt.plot(predictions[2][-25:], color=\"purple\", label=\"forecast\")\n",
    "#plt.plot(predictions[3][-25:], color=\"orange\", label=\"forecast\")\n",
    "plt.plot(predictions[0][-200:], color=\"brown\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"font-size:1.5em;\">Testing on simpler data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/AileenNielsen/TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\")\n",
    "\n",
    "# We create shifts of the #Passengers\n",
    "df['#Passengers_shift1'] = df['#Passengers'].shift(-1)\n",
    "df['#Passengers_shift2'] = df['#Passengers'].shift(-2)\n",
    "df['#Passengers_shift3'] = df['#Passengers'].shift(-3)\n",
    "df['#Passengers_shift4'] = df['#Passengers'].shift(-4)\n",
    "df['Month'] = df['Month'].str[-2:]\n",
    "\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "model = RandomForestRegressor(n_estimators= 100,\n",
    "                             n_jobs=6,\n",
    "                             random_state=42)\n",
    "\n",
    "horizon_max = 5\n",
    "day_len = 30\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon_max)]\n",
    "\n",
    "# List for storing the predictions (useful for visualization)\n",
    "predictions = []\n",
    "for horizon in range (1, horizon_max+1, 1):\n",
    "    # Define the train and test set\n",
    "    X_train = df[['Month', '#Passengers_shift1', '#Passengers_shift2', '#Passengers_shift3', '#Passengers_shift4']][:-(day_len + horizon)]\n",
    "    y_train = df['#Passengers'][horizon:-day_len]\n",
    "    X_test = df[['Month', '#Passengers_shift1', '#Passengers_shift2', '#Passengers_shift3', '#Passengers_shift4']][-(day_len + horizon):-horizon]\n",
    "    y_test = df['#Passengers'][-day_len:]\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make predictions\n",
    "    forecast = model.predict(X_test).tolist()\n",
    "    # Store to the predictions\n",
    "    predictions.append(forecast)\n",
    "    \n",
    "    # Calculate and save the r2 score\n",
    "    r2_scores[horizon-1].append(r2_score(y_test, forecast))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_index = list(range(len(df['#Passengers'])-day_len, len(df['#Passengers'])))\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df[\"#Passengers\"][-30:], color=\"royalblue\", label=\"historical data\")\n",
    "plt.plot(forecast_index[-30:], predictions[0][-30:], color=\"tomato\", label=\"forecast\")\n",
    "plt.plot(forecast_index[-30:], predictions[1][-30:], color=\"green\", label=\"forecast\")\n",
    "plt.plot(forecast_index[-30:], predictions[2][-30:], color=\"orange\", label=\"forecast\")\n",
    "plt.plot(forecast_index[-30:], predictions[3][-30:], color=\"grey\", label=\"forecast\")\n",
    "plt.plot(forecast_index[-30:], predictions[4][-30:], color=\"brown\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <span style=\"font-size:1.5em;\">Ploting precipitation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['altitude_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[2][-200:], color=\"tomato\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[2][-200:], color=\"green\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[4][-200:], color=\"grey\", label=\"forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['precipitation_probability_max'][-200:].apply(lambda x: x/20), color=\"brown\", label=\"forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['precipitation'][-200:].apply(lambda x: x/130), color=\"olive\", label=\"forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['precipitation_intensity_max'][-200:].apply(lambda x: x/130), color=\"salmon\", label=\"forecast\")\n",
    "plt.savefig('../data/interim/plot.svg', format='svg')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final prediction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add the predictions\n",
    "def weather_forecast(X_train):\n",
    "    postfixes = ['avg', 'min', 'max']\n",
    "    for i in range(1,6):\n",
    "        for postfix in postfixes:\n",
    "            X_train[f\"precipitation_probability_{postfix}_shift-{i}\"] = X_train[f'precipitation_probability_{postfix}'].shift(-i)\n",
    "            X_train[f\"precipitation_intensity_{postfix}_shift-{i}\"] = X_train[f'precipitation_intensity_{postfix}'].shift(-i)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aquifer in aquifers_list:\n",
    "    aquifer_by_stations[aquifer] = weather_forecast(aquifer_by_stations[aquifer])\n",
    "    aquifer_by_stations[aquifer] = aquifer_by_stations[aquifer][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''{'n_estimators': 51,\n",
    " 'criterion': 'squared_error',\n",
    " 'max_depth': 20,\n",
    " 'min_samples_split': 9,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_features': 0.36336466788790966,\n",
    " 'oob_score': True,\n",
    " 'max_leaf_nodes': 10,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'ccp_alpha': 0.0}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "model = RandomForestRegressor(n_estimators= 200,\n",
    "                             #criterion= 'squared_error',\n",
    "                             #max_depth= 50,\n",
    "                             #min_samples_split= 9,\n",
    "                             #min_samples_leaf= 4,\n",
    "                             max_features= 'sqrt',\n",
    "                             #bootstrap= True,\n",
    "                             #oob_score= True,\n",
    "                             #max_leaf_nodes= 10,\n",
    "                             #min_impurity_decrease= 0.0,\n",
    "                             #ccp_alpha= 0.0,\n",
    "                             #max_samples= None,\n",
    "                             n_jobs=6,\n",
    "                             random_state=42)\n",
    "\n",
    "horizon_max = 5\n",
    "day_len = 365\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon_max)]\n",
    "\n",
    "# List for storing the predictions (useful for visualization)\n",
    "predictions = []\n",
    "\n",
    "for aquifer in aquifers_list:\n",
    "    predictions = [] # make sure that the list is empty for every aquifer\n",
    "\n",
    "    for horizon in range (1, horizon_max+1, 1):\n",
    "        # Define the train and test set\n",
    "        X_train = aquifer_by_stations[aquifer][best_features][:-(day_len + horizon)]\n",
    "        y_train = aquifer_by_stations[aquifer][features_target][horizon:-day_len]\n",
    "\n",
    "        X_test = aquifer_by_stations[aquifer][best_features][-(day_len + horizon):-horizon]\n",
    "        y_test = aquifer_by_stations[aquifer][features_target][-day_len:]\n",
    "\n",
    "        # Choose the best hyperparameter for the station and horizon\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = model.predict(X_test).tolist()\n",
    "\n",
    "        # Store to the predictions\n",
    "        predictions.append(forecast)\n",
    "        \n",
    "        # Calculate and save the r2 score\n",
    "        r2_scores[horizon-1].append(r2_score(y_test, forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['altitude_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[0][-200:], color=\"tomato\", label=\"forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[2][-200:], color=\"green\", label=\"forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[4][-200:], color=\"grey\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['precipitation_probability_max'][-200:].apply(lambda x: x/20), color=\"brown\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['precipitation'][-200:].apply(lambda x: x/130), color=\"olive\", label=\"forecast\")\n",
    "plt.savefig('../data/interim/plot.svg', format='svg')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/randomforest/n-hits-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/randomforest/n-hits-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/randomforest/n-hits-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.2** Surface water data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "watercourse_by_stations = joblib.load('../data/interim/surface-water-and-weather.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters, that we want to keep in the data\n",
    "features_target = ['level_diff']\n",
    "features_train = ['year', 'month', 'day','level_diff_shift1', 'level_diff_shift2', 'level_diff_shift3', \n",
    "                  'level_diff_shift4', 'level_diff_shift5', 'precipitation_intensity_avg_average2', \n",
    "                  'precipitation_average2', 'precipitation_intensity_max_average2', \n",
    "                  'precipitation_probability_avg_average2', 'precipitation_intensity_avg', \n",
    "                  'precipitation_intensity_avg_shift1', 'precipitation', 'precipitation_shift1', \n",
    "                  'precipitation_intensity_avg_average3', 'precipitation_probability_avg_shift1', \n",
    "                  'precipitation_probability_avg', 'precipitation_average3', 'precipitation_intensity_max', \n",
    "                  'precipitation_intensity_max_shift1', 'precipitation_probability_max_average2', \n",
    "                  'precipitation_probability_avg_average3', 'precipitation_intensity_max_average3', \n",
    "                  'precipitation_probability_max', 'precipitation_probability_max_shift1', 'precipitation_probability_max_average3', \n",
    "                  'precipitation_intensity_avg_average4', 'precipitation_average4', 'precipitation_probability_avg_average4', \n",
    "                  'precipitation_probability_min_average2', 'precipitation_intensity_max_average4', \n",
    "                  'precipitation_probability_avg_shift1_average2', 'precipitation_intensity_avg_shift1_average2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date column to year, month and day columns\n",
    "for key in watercourse_by_stations.keys():\n",
    "    watercourse_by_stations[key]['year'] = watercourse_by_stations[key]['date'].dt.year\n",
    "    watercourse_by_stations[key]['month'] = watercourse_by_stations[key]['date'].dt.month\n",
    "    watercourse_by_stations[key]['day'] = watercourse_by_stations[key]['date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "watercourse_by_stations = joblib.load('../data/interim/surface-water-and-weather.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = 2530\n",
    "day_len = 365\n",
    "horizon = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = watercourse_by_stations[station][:-(day_len + horizon)].drop(columns=['level_diff', 'level', 'date'])\n",
    "y_train = watercourse_by_stations[station][features_target][horizon:-day_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions\n",
    "postfixes = ['avg', 'min', 'max']\n",
    "for i in range(1,6):\n",
    "    for postfix in postfixes:\n",
    "        X_train[f\"precipitation_probability_{postfix}_shift-{i}\"] = X_train[f'precipitation_probability_{postfix}'].shift(-i)\n",
    "        X_train[f\"precipitation_intensity_{postfix}_shift-{i}\"] = X_train[f'precipitation_intensity_{postfix}'].shift(-i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last 5 values\n",
    "X_train = X_train[:-5]\n",
    "y_train = y_train[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series split\n",
    "tscv = TimeSeriesSplit(n_splits=2)\n",
    "\n",
    "# Initialize model\n",
    "model = LinearRegression(n_jobs=4)\n",
    "\n",
    "# Initialize genetic algorithm feature selector with max_features set\n",
    "gafs = GAFeatureSelectionCV(\n",
    "    estimator=model,\n",
    "    cv=tscv,\n",
    "    scoring=\"r2\",\n",
    "    population_size=200,\n",
    "    generations=35,\n",
    "    n_jobs=-1,\n",
    "    verbose=True,\n",
    "    keep_top_k=5,\n",
    "    elitism=True,\n",
    "    max_features=40,  # Set the maximum number of features to select\n",
    "    mutation_probability=0.2,\n",
    "    crossover_probability=0.8\n",
    ")\n",
    "\n",
    "# Fit the feature selector\n",
    "gafs.fit(X_train, y_train)\n",
    "\n",
    "# Plot fitness evolution\n",
    "plot_fitness_evolution(gafs)\n",
    "# Output best features found\n",
    "print(\"Best Features Found:\", gafs.best_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gafs.best_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best features to a list\n",
    "best_features = [item for item, keep in zip(X_train.columns, gafs.best_features_) if keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon, day_len (number of predicted days), test_len (number of days used for final testing)\n",
    "horizon_max = 5\n",
    "day_len = 100\n",
    "test_len = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations to test\n",
    "station_list = [4270, 4570, 4515, 6068]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth = trial.suggest_categorical('max_depth', [None, 10, 20, 30, 50])\n",
    "    max_features = trial.suggest_categorical('max_features', [\"sqrt\", \"auto\", \"auto\", None])\n",
    "\n",
    "    # Initialize the RandomForestClassifier\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  max_features=max_features,\n",
    "                                  n_jobs=6,\n",
    "                                  random_state=42)\n",
    "    \n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon_max)]\n",
    "    \n",
    "    for station in station_list:\n",
    "    \n",
    "        for horizon in range (1, horizon_max+1, 1):\n",
    "            # Define the train and test set\n",
    "            X_train = watercourse_by_stations[station][features_train][:-(day_len + horizon + test_len)]\n",
    "            y_train = watercourse_by_stations[station][features_target][horizon:-(day_len + test_len)]\n",
    "    \n",
    "            X_test = watercourse_by_stations[station][features_train][-(day_len + horizon + test_len):-(horizon + test_len)]\n",
    "            y_test = watercourse_by_stations[station][features_target][-(day_len + test_len):-test_len]\n",
    "    \n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "    \n",
    "            # Make predictions\n",
    "            forecast = model.predict(X_test).tolist()\n",
    "            \n",
    "            # Calculate and save the r2 score\n",
    "            r2_scores[horizon-1].append(r2_score(y_test, forecast))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best features\n",
    "'''['precipitation_shift1',\n",
    " 'snow_accumulation_shift10',\n",
    " 'temperature_avg_shift1',\n",
    " 'precipitation_probability_max_shift7',\n",
    " 'level_diff_average3',\n",
    " 'precipitation_average2',\n",
    " 'precipitation_probability_min_average10',\n",
    " 'precipitation_shift8_average4',\n",
    " 'snow_accumulation_shift4_average2',\n",
    " 'temperature_min_shift2_average4',\n",
    " 'temperature_max_shift1_average4',\n",
    " 'temperature_max_shift4_average4',\n",
    " 'cloud_cover_min_shift2_average2',\n",
    " 'cloud_cover_max_shift4_average7',\n",
    " 'cloud_cover_max_shift9_average3',\n",
    " 'humidity_avg_shift2_average6',\n",
    " 'humidity_avg_shift7_average9',\n",
    " 'humidity_avg_shift10_average5',\n",
    " 'humidity_min_shift2_average10',\n",
    " 'humidity_min_shift6_average5',\n",
    " 'humidity_min_shift6_average9',\n",
    " 'humidity_max_shift8_average6',\n",
    " 'precipitation_probability_avg_shift5_average7',\n",
    " 'precipitation_probability_avg_shift9_average6',\n",
    " 'precipitation_probability_avg_shift10_average2',\n",
    " 'precipitation_probability_avg_shift10_average4',\n",
    " 'precipitation_intensity_avg_shift3_average5',\n",
    " 'precipitation_intensity_max_shift2_average6',\n",
    " 'precipitation_intensity_max_shift7_average10',\n",
    " 'precipitation_intensity_max_shift10_average10',\n",
    " 'day',\n",
    " 'precipitation_intensity_max_shift-5',\n",
    " 'precipitation_intensity_max_shift-4',\n",
    " 'precipitation_intensity_max_shift-3',\n",
    " 'precipitation_intensity_max_shift-2',\n",
    " 'precipitation_intensity_max_shift-1']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['precipitation_shift1',\n",
    " 'snow_accumulation_shift10',\n",
    " 'temperature_avg_shift1',\n",
    " 'precipitation_probability_max_shift7',\n",
    " 'level_diff_average3',\n",
    " 'precipitation_average2',\n",
    " 'precipitation_probability_min_average10',\n",
    " 'precipitation_shift8_average4',\n",
    " 'snow_accumulation_shift4_average2',\n",
    " 'temperature_min_shift2_average4',\n",
    " 'temperature_max_shift1_average4',\n",
    " 'temperature_max_shift4_average4',\n",
    " 'cloud_cover_min_shift2_average2',\n",
    " 'cloud_cover_max_shift4_average7',\n",
    " 'cloud_cover_max_shift9_average3',\n",
    " 'humidity_avg_shift2_average6',\n",
    " 'humidity_avg_shift7_average9',\n",
    " 'humidity_avg_shift10_average5',\n",
    " 'humidity_min_shift2_average10',\n",
    " 'humidity_min_shift6_average5',\n",
    " 'humidity_min_shift6_average9',\n",
    " 'humidity_max_shift8_average6',\n",
    " 'precipitation_probability_avg_shift5_average7',\n",
    " 'precipitation_probability_avg_shift9_average6',\n",
    " 'precipitation_probability_avg_shift10_average2',\n",
    " 'precipitation_probability_avg_shift10_average4',\n",
    " 'precipitation_intensity_avg_shift3_average5',\n",
    " 'precipitation_intensity_max_shift2_average6',\n",
    " 'precipitation_intensity_max_shift7_average10',\n",
    " 'precipitation_intensity_max_shift10_average10',\n",
    " 'day',\n",
    " 'precipitation_intensity_max_shift-5',\n",
    " 'precipitation_intensity_max_shift-4',\n",
    " 'precipitation_intensity_max_shift-3',\n",
    " 'precipitation_intensity_max_shift-2',\n",
    " 'precipitation_intensity_max_shift-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of station used for testing\n",
    "station_list = [2530, 2620, 4200, 4230, 4270, 4515, 4520, 4570, 4575, 5040, 5078, 5330, 5425, 5500, 6060, 6068, 6200, 6220, 6300, 6340, 8454, 8565]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the weather forecast features\n",
    "for station in station_list:\n",
    "    watercourse_by_stations[station] = weather_forecast(watercourse_by_stations[station])\n",
    "    # Get rid of the last 5 rows\n",
    "    watercourse_by_stations[station] = watercourse_by_stations[station][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = [2530]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "model = RandomForestRegressor(n_estimators= 250,\n",
    "                             #criterion= 'squared_error',\n",
    "                             #max_depth= 20,\n",
    "                             #min_samples_split= 9,\n",
    "                             #min_samples_leaf= 4,\n",
    "                             #max_features= 0.36336466788790966,\n",
    "                             #bootstrap= True,\n",
    "                             #oob_score= True,\n",
    "                             #max_leaf_nodes= 10,\n",
    "                             #min_impurity_decrease= 0.0,\n",
    "                             #ccp_alpha= 0.0,\n",
    "                             #max_samples= None,\n",
    "                             n_jobs=6,\n",
    "                             random_state=42)\n",
    "\n",
    "horizon_max = 5\n",
    "day_len = 365\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon_max)]\n",
    "\n",
    "# List for storing the predictions (useful for visualization)\n",
    "predictions = []\n",
    "\n",
    "for station in station_list:\n",
    "    predictions = []\n",
    "\n",
    "    for horizon in range (1, horizon_max+1, 1):\n",
    "        # Define the train and test set\n",
    "        X_train = watercourse_by_stations[station][best_features][:-(day_len + horizon)]\n",
    "        y_train = watercourse_by_stations[station][features_target][horizon:-day_len]\n",
    "\n",
    "        X_test = watercourse_by_stations[station][best_features][-(day_len + horizon):-horizon]\n",
    "        y_test = watercourse_by_stations[station][features_target][-day_len:]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = model.predict(X_test).tolist()\n",
    "\n",
    "        # Store to the predictions\n",
    "        predictions.append(forecast)\n",
    "        \n",
    "        # Calculate and save the r2 score\n",
    "        r2_scores[horizon-1].append(r2_score(y_test, forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(watercourse_by_stations[station]['date'][-150:-80], watercourse_by_stations[station]['level_diff'][-150:-80], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(watercourse_by_stations[station]['date'][-150:-80], predictions[0][-150:-80], color=\"tomato\", label=\"forecast\")\n",
    "plt.plot(watercourse_by_stations[station]['date'][-150:-80], predictions[1][-150:-80], color=\"green\", label=\"forecast\")\n",
    "plt.plot(watercourse_by_stations[station]['date'][-150:-80], predictions[2][-150:-80], color=\"orange\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/randomforest/n-hits-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/randomforest/n-hits-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/randomforest/n-hits-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2** Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1** Ground water data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "aquifer_by_stations = joblib.load('../data/interim/ground-water-and-weather.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters, that we want to keep in the data\n",
    "features_target = ['altitude_diff']\n",
    "features_train = ['year', 'month', 'day','altitude_diff_shift1', 'altitude_diff_shift2', 'altitude_diff_shift3', 'altitude_diff_shift4', 'altitude_diff_shift5', 'precipitation_average4', 'precipitation_average3', 'precipitation_average5', 'precipitation_average6', 'precipitation_average7', 'precipitation_shift1_average2', 'precipitation_shift1_average3', 'precipitation_average2', 'precipitation_shift1_average4', 'precipitation_average8', 'precipitation_shift1_average5', 'precipitation_average9', 'precipitation_shift1', 'precipitation_average10', 'precipitation_shift1_average6', 'precipitation_shift1_average7', 'precipitation_shift1_average8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date column to year, month and day columns\n",
    "for key in aquifer_by_stations.keys():\n",
    "    aquifer_by_stations[key]['year'] = aquifer_by_stations[key]['date'].dt.year\n",
    "    aquifer_by_stations[key]['month'] = aquifer_by_stations[key]['date'].dt.month\n",
    "    aquifer_by_stations[key]['day'] = aquifer_by_stations[key]['date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best features longer validation\n",
    "best_features =  ['temperature_min',\n",
    " 'snow_accumulation_average6',\n",
    " 'temperature_avg_average2',\n",
    " 'cloud_cover_max_average3',\n",
    " 'humidity_avg_average4',\n",
    " 'precipitation_probability_avg_average2',\n",
    " 'precipitation_probability_max_average5',\n",
    " 'precipitation_intensity_avg_average6',\n",
    " 'snow_accumulation_shift1_average4',\n",
    " 'temperature_min_shift1_average3',\n",
    " 'temperature_min_shift3_average6',\n",
    " 'temperature_min_shift9_average5',\n",
    " 'temperature_max_shift4_average2',\n",
    " 'temperature_max_shift6_average6',\n",
    " 'humidity_avg_shift10_average2',\n",
    " 'humidity_min_shift8_average2',\n",
    " 'humidity_min_shift9_average8',\n",
    " 'humidity_min_shift10_average5',\n",
    " 'humidity_max_shift3_average10',\n",
    " 'humidity_max_shift8_average8',\n",
    " 'humidity_max_shift8_average9',\n",
    " 'precipitation_probability_min_shift7_average4',\n",
    " 'precipitation_probability_min_shift9_average10',\n",
    " 'precipitation_probability_max_shift5_average10',\n",
    " 'precipitation_probability_max_shift10_average3',\n",
    " 'precipitation_intensity_avg_shift2_average2',\n",
    " 'precipitation_intensity_min_shift5_average4',\n",
    " 'precipitation_intensity_max_shift2_average10',\n",
    " 'precipitation_intensity_max_shift4_average5',\n",
    " 'precipitation_probability_avg_shift-1',\n",
    " 'precipitation_probability_avg_shift-2',\n",
    " 'precipitation_probability_max_shift-2',\n",
    " 'precipitation_intensity_max_shift-3',\n",
    " # manually added\n",
    " 'precipitation_probability_avg_shift-5',\n",
    " 'precipitation_probability_avg_shift-4',\n",
    " 'precipitation_probability_avg_shift-3'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions\n",
    "def weather_forecast(X_train):\n",
    "    postfixes = ['avg', 'min', 'max']\n",
    "    for i in range(1,6):\n",
    "        for postfix in postfixes:\n",
    "            X_train[f\"precipitation_probability_{postfix}_shift-{i}\"] = X_train[f'precipitation_probability_{postfix}'].shift(-i)\n",
    "            X_train[f\"precipitation_intensity_{postfix}_shift-{i}\"] = X_train[f'precipitation_intensity_{postfix}'].shift(-i)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aquifer in aquifers_list:\n",
    "    aquifer_by_stations[aquifer] = weather_forecast(aquifer_by_stations[aquifer])\n",
    "    aquifer_by_stations[aquifer] = aquifer_by_stations[aquifer][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon, day_len (number of predicted days), test_len (number of days used for final testing)\n",
    "horizon_max = 5\n",
    "day_len = 100\n",
    "test_len = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n",
    "    max_depth = trial.suggest_categorical('max_depth', [None, 10, 20, 30, 50])\n",
    "    max_features = trial.suggest_categorical('max_features', [\"sqrt\", \"log2\", 0.5, 1.0])\n",
    "\n",
    "\n",
    "    # Initialize the RandomForestClassifier\n",
    "    model = GradientBoostingRegressor(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  max_features=max_features,\n",
    "                                  random_state=42)\n",
    "    \n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon_max)]\n",
    "    \n",
    "    for aquifer in aquifers_list:\n",
    "    \n",
    "        for horizon in range (1, horizon_max+1, 1):\n",
    "            # Define the train and test set\n",
    "            X_train = aquifer_by_stations[aquifer][best_features][:-(day_len + horizon + test_len)]\n",
    "            y_train = aquifer_by_stations[aquifer][features_target][horizon:-(day_len + test_len)]\n",
    "    \n",
    "            X_test = aquifer_by_stations[aquifer][best_features][-(day_len + horizon + test_len):-(horizon + test_len)]\n",
    "            y_test = aquifer_by_stations[aquifer][features_target][-(day_len + test_len):-test_len]\n",
    "    \n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "    \n",
    "            # Make predictions\n",
    "            forecast = model.predict(X_test).tolist()\n",
    "            \n",
    "            # Calculate and save the r2 score\n",
    "            r2_scores[horizon-1].append(r2_score(y_test, forecast))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "aquifer_by_stations = joblib.load('../data/interim/ground-water-and-weather.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters, that we want to keep in the data\n",
    "features_target = ['altitude_diff']\n",
    "features_train = ['year', 'month', 'day','altitude_diff_shift1', 'altitude_diff_shift2', 'altitude_diff_shift3', 'altitude_diff_shift4', 'altitude_diff_shift5', 'precipitation_average4', 'precipitation_average3', 'precipitation_average5', 'precipitation_average6', 'precipitation_average7', 'precipitation_shift1_average2', 'precipitation_shift1_average3', 'precipitation_average2', 'precipitation_shift1_average4', 'precipitation_average8', 'precipitation_shift1_average5', 'precipitation_average9', 'precipitation_shift1', 'precipitation_average10', 'precipitation_shift1_average6', 'precipitation_shift1_average7', 'precipitation_shift1_average8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date column to year, month and day columns\n",
    "for key in aquifer_by_stations.keys():\n",
    "    aquifer_by_stations[key]['year'] = aquifer_by_stations[key]['date'].dt.year\n",
    "    aquifer_by_stations[key]['month'] = aquifer_by_stations[key]['date'].dt.month\n",
    "    aquifer_by_stations[key]['day'] = aquifer_by_stations[key]['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best features longer validation\n",
    "best_features =  ['temperature_min',\n",
    " 'snow_accumulation_average6',\n",
    " 'temperature_avg_average2',\n",
    " 'cloud_cover_max_average3',\n",
    " 'humidity_avg_average4',\n",
    " 'precipitation_probability_avg_average2',\n",
    " 'precipitation_probability_max_average5',\n",
    " 'precipitation_intensity_avg_average6',\n",
    " 'snow_accumulation_shift1_average4',\n",
    " 'temperature_min_shift1_average3',\n",
    " 'temperature_min_shift3_average6',\n",
    " 'temperature_min_shift9_average5',\n",
    " 'temperature_max_shift4_average2',\n",
    " 'temperature_max_shift6_average6',\n",
    " 'humidity_avg_shift10_average2',\n",
    " 'humidity_min_shift8_average2',\n",
    " 'humidity_min_shift9_average8',\n",
    " 'humidity_min_shift10_average5',\n",
    " 'humidity_max_shift3_average10',\n",
    " 'humidity_max_shift8_average8',\n",
    " 'humidity_max_shift8_average9',\n",
    " 'precipitation_probability_min_shift7_average4',\n",
    " 'precipitation_probability_min_shift9_average10',\n",
    " 'precipitation_probability_max_shift5_average10',\n",
    " 'precipitation_probability_max_shift10_average3',\n",
    " 'precipitation_intensity_avg_shift2_average2',\n",
    " 'precipitation_intensity_min_shift5_average4',\n",
    " 'precipitation_intensity_max_shift2_average10',\n",
    " 'precipitation_intensity_max_shift4_average5',\n",
    " 'precipitation_probability_avg_shift-1',\n",
    " 'precipitation_probability_avg_shift-2',\n",
    " 'precipitation_probability_max_shift-2',\n",
    " 'precipitation_intensity_max_shift-3',\n",
    " # manually added\n",
    " 'precipitation_probability_avg_shift-5',\n",
    " 'precipitation_probability_avg_shift-4',\n",
    " 'precipitation_probability_avg_shift-3'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions\n",
    "def weather_forecast(X_train):\n",
    "    postfixes = ['avg', 'min', 'max']\n",
    "    for i in range(1,6):\n",
    "        for postfix in postfixes:\n",
    "            X_train[f\"precipitation_probability_{postfix}_shift-{i}\"] = X_train[f'precipitation_probability_{postfix}'].shift(-i)\n",
    "            X_train[f\"precipitation_intensity_{postfix}_shift-{i}\"] = X_train[f'precipitation_intensity_{postfix}'].shift(-i)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aquifer in aquifers_list:\n",
    "    aquifer_by_stations[aquifer] = weather_forecast(aquifer_by_stations[aquifer])\n",
    "    aquifer_by_stations[aquifer] = aquifer_by_stations[aquifer][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters for n_estimators=10\n",
    "'''{'n_estimators': 28, 'max_depth': 10, 'max_features': 'log2'}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters for n_estimators=50\n",
    "'''{'n_estimators': 140, 'max_depth': 30, 'max_features': 'sqrt'}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(n_estimators=28, max_features='log2', max_depth=10, random_state=42)\n",
    "\n",
    "horizon_max = 5\n",
    "day_len = 365\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon_max)]\n",
    "\n",
    "# Dictionary for storing the predictions for all of the stations\n",
    "predictions_by_stations = {key: [] for key in aquifers_list}\n",
    "\n",
    "for aquifer in aquifers_list:\n",
    "    predictions = []\n",
    "\n",
    "    for horizon in range (1, horizon_max+1, 1):\n",
    "        # Define the train and test set\n",
    "        X_train = aquifer_by_stations[aquifer][best_features][:-(day_len + horizon)]\n",
    "        y_train = aquifer_by_stations[aquifer][features_target][horizon:-day_len]\n",
    "\n",
    "        X_test = aquifer_by_stations[aquifer][best_features][-(day_len + horizon):-horizon]\n",
    "        y_test = aquifer_by_stations[aquifer][features_target][-day_len:]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = model.predict(X_test).tolist()\n",
    "\n",
    "        # Store to the predictions\n",
    "        predictions.append(forecast)\n",
    "        \n",
    "        # Calculate and save the r2 score\n",
    "        r2_scores[horizon-1].append(r2_score(y_test, forecast))\n",
    "\n",
    "    predictions_by_stations[aquifer] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-100:-60], aquifer_by_stations[aquifer]['altitude_diff'][-100:-60], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-100:-60], predictions[0][-100:-60], color=\"tomato\", label=\"forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-100:-60], predictions[1][-100:-60], color=\"green\", label=\"forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-100:-60], predictions_by_stations[85064][0][-100:-60], color=\"orange\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/gradient-boosting/gradient-boosting-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/gradient-boosting/gradient-boosting-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/gradient-boosting/gradient-boosting-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(predictions_by_stations, '../reports/gradient-boosting/gradient-boosting-ground-water-predictions.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2** Surface water data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "watercourse_by_stations = joblib.load('../data/interim/surface-water-and-weather.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters, that we want to keep in the data\n",
    "features_target = ['level_diff']\n",
    "features_train = ['year', 'month', 'day','level_diff_shift1', 'level_diff_shift2', 'level_diff_shift3', \n",
    "                  'level_diff_shift4', 'level_diff_shift5', 'precipitation_intensity_avg_average2', \n",
    "                  'precipitation_average2', 'precipitation_intensity_max_average2', \n",
    "                  'precipitation_probability_avg_average2', 'precipitation_intensity_avg', \n",
    "                  'precipitation_intensity_avg_shift1', 'precipitation', 'precipitation_shift1', \n",
    "                  'precipitation_intensity_avg_average3', 'precipitation_probability_avg_shift1', \n",
    "                  'precipitation_probability_avg', 'precipitation_average3', 'precipitation_intensity_max', \n",
    "                  'precipitation_intensity_max_shift1', 'precipitation_probability_max_average2', \n",
    "                  'precipitation_probability_avg_average3', 'precipitation_intensity_max_average3', \n",
    "                  'precipitation_probability_max', 'precipitation_probability_max_shift1', 'precipitation_probability_max_average3', \n",
    "                  'precipitation_intensity_avg_average4', 'precipitation_average4', 'precipitation_probability_avg_average4', \n",
    "                  'precipitation_probability_min_average2', 'precipitation_intensity_max_average4', \n",
    "                  'precipitation_probability_avg_shift1_average2', 'precipitation_intensity_avg_shift1_average2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date column to year, month and day columns\n",
    "for key in watercourse_by_stations.keys():\n",
    "    watercourse_by_stations[key]['year'] = watercourse_by_stations[key]['date'].dt.year\n",
    "    watercourse_by_stations[key]['month'] = watercourse_by_stations[key]['date'].dt.month\n",
    "    watercourse_by_stations[key]['day'] = watercourse_by_stations[key]['date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon, day_len (number of predicted days), test_len (number of days used for final testing)\n",
    "horizon_max = 5\n",
    "day_len = 100\n",
    "test_len = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations to test\n",
    "station_list = [4270, 4570, 4515, 6068]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.0, 1.0)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 9)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    max_features = trial.suggest_float('max_features', 0.5, 1.0)\n",
    "    loss = trial.suggest_categorical('loss', ['squared_error', 'absolute_error', 'huber'])\n",
    "    tol = trial.suggest_float('tol', 1e-4, 1e-2)\n",
    "    n_iter_no_change = trial.suggest_categorical('n_iter_no_change', [None, 5, 10, 20])\n",
    "\n",
    "\n",
    "    # Initialize the RandomForestClassifier\n",
    "    model = GradientBoostingRegressor(n_estimators=n_estimators,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  max_depth=max_depth,\n",
    "                                  min_samples_split=min_samples_split,\n",
    "                                  min_samples_leaf=min_samples_leaf,\n",
    "                                  subsample=subsample,\n",
    "                                  max_features=max_features,\n",
    "                                  tol=tol,\n",
    "                                  n_iter_no_change=n_iter_no_change,\n",
    "                                  random_state=42)\n",
    "    \n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon_max)]\n",
    "    \n",
    "    for station in station_list:\n",
    "    \n",
    "        for horizon in range (1, horizon_max+1, 1):\n",
    "            # Define the train and test set\n",
    "            X_train = watercourse_by_stations[station][features_train][:-(day_len + horizon + test_len)]\n",
    "            y_train = watercourse_by_stations[station][features_target][horizon:-(day_len + test_len)]\n",
    "    \n",
    "            X_test = watercourse_by_stations[station][features_train][-(day_len + horizon + test_len):-(horizon + test_len)]\n",
    "            y_test = watercourse_by_stations[station][features_target][-(day_len + test_len):-test_len]\n",
    "    \n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "    \n",
    "            # Make predictions\n",
    "            forecast = model.predict(X_test).tolist()\n",
    "            \n",
    "            # Calculate and save the r2 score\n",
    "            r2_scores[horizon-1].append(r2_score(y_test, forecast))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = ['precipitation_shift1',\n",
    " 'snow_accumulation_shift10',\n",
    " 'temperature_avg_shift1',\n",
    " 'precipitation_probability_max_shift7',\n",
    " 'level_diff_average3',\n",
    " 'precipitation_average2',\n",
    " 'precipitation_probability_min_average10',\n",
    " 'precipitation_shift8_average4',\n",
    " 'snow_accumulation_shift4_average2',\n",
    " 'temperature_min_shift2_average4',\n",
    " 'temperature_max_shift1_average4',\n",
    " 'temperature_max_shift4_average4',\n",
    " 'cloud_cover_min_shift2_average2',\n",
    " 'cloud_cover_max_shift4_average7',\n",
    " 'cloud_cover_max_shift9_average3',\n",
    " 'humidity_avg_shift2_average6',\n",
    " 'humidity_avg_shift7_average9',\n",
    " 'humidity_avg_shift10_average5',\n",
    " 'humidity_min_shift2_average10',\n",
    " 'humidity_min_shift6_average5',\n",
    " 'humidity_min_shift6_average9',\n",
    " 'humidity_max_shift8_average6',\n",
    " 'precipitation_probability_avg_shift5_average7',\n",
    " 'precipitation_probability_avg_shift9_average6',\n",
    " 'precipitation_probability_avg_shift10_average2',\n",
    " 'precipitation_probability_avg_shift10_average4',\n",
    " 'precipitation_intensity_avg_shift3_average5',\n",
    " 'precipitation_intensity_max_shift2_average6',\n",
    " 'precipitation_intensity_max_shift7_average10',\n",
    " 'precipitation_intensity_max_shift10_average10',\n",
    " 'day',\n",
    " 'precipitation_intensity_max_shift-5',\n",
    " 'precipitation_intensity_max_shift-4',\n",
    " 'precipitation_intensity_max_shift-3',\n",
    " 'precipitation_intensity_max_shift-2',\n",
    " 'precipitation_intensity_max_shift-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of station used for testing\n",
    "station_list = [2530, 2620, 4200, 4230, 4270, 4515, 4520, 4570, 4575, 5040, 5078, 5330, 5425, 5500, 6060, 6068, 6200, 6220, 6300, 6340, 8454, 8565]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "# Initialize the GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "horizon_max = 5\n",
    "day_len = 365\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon_max)]\n",
    "\n",
    "# List for storing the predictions (useful for visualization)\n",
    "predictions = []\n",
    "\n",
    "for station in station_list:\n",
    "    predictions = []\n",
    "\n",
    "    for horizon in range (1, horizon_max+1, 1):\n",
    "        # Define the train and test set\n",
    "        X_train = watercourse_by_stations[station][features_train][:-(day_len + horizon)]\n",
    "        y_train = watercourse_by_stations[station][features_target][horizon:-day_len]\n",
    "\n",
    "        X_test = watercourse_by_stations[station][features_train][-(day_len + horizon):-horizon]\n",
    "        y_test = watercourse_by_stations[station][features_target][-day_len:]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = model.predict(X_test).tolist()\n",
    "\n",
    "        # Store to the predictions\n",
    "        predictions.append(forecast)\n",
    "        \n",
    "        # Calculate and save the r2 score\n",
    "        r2_scores[horizon-1].append(r2_score(y_test, forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(watercourse_by_stations[aquifer]['date'][-100:-60], watercourse_by_stations[aquifer]['altitude_diff'][-100:-60], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(watercourse_by_stations[aquifer]['date'][-100:-60], predictions[0][-100:-60], color=\"tomato\", label=\"forecast\")\n",
    "plt.plot(watercourse_by_stations[aquifer]['date'][-100:-60], predictions[1][-100:-60], color=\"green\", label=\"forecast\")\n",
    "plt.plot(watercourse_by_stations[aquifer]['date'][-100:-60], predictions[2][-100:-60], color=\"orange\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/randomforest/n-hits-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/randomforest/n-hits-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/randomforest/n-hits-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3** Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1** Ground water data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "aquifer_by_stations = joblib.load('../data/interim/ground-water-and-weather.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target feature\n",
    "features_target = ['altitude_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date column to year, month and day columns\n",
    "for key in aquifer_by_stations.keys():\n",
    "    aquifer_by_stations[key]['year'] = aquifer_by_stations[key]['date'].dt.year\n",
    "    aquifer_by_stations[key]['month'] = aquifer_by_stations[key]['date'].dt.month\n",
    "    aquifer_by_stations[key]['day'] = aquifer_by_stations[key]['date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best features for validation 365 days\n",
    "best_features = ['cloud_cover_min_shift5',\n",
    " 'precipitation_intensity_avg_shift3',\n",
    " 'precipitation_intensity_max_shift2',\n",
    " 'temperature_avg_average6',\n",
    " 'cloud_cover_max_average7',\n",
    " 'humidity_min_average4',\n",
    " 'precipitation_probability_avg_average4',\n",
    " 'precipitation_probability_max_average2',\n",
    " 'precipitation_intensity_avg_average2',\n",
    " 'altitude_diff_shift2_average3',\n",
    " 'altitude_diff_shift5_average10',\n",
    " 'altitude_diff_shift7_average2',\n",
    " 'altitude_diff_shift9_average6',\n",
    " 'altitude_diff_shift10_average4',\n",
    " 'precipitation_shift10_average4',\n",
    " 'temperature_min_shift8_average3',\n",
    " 'temperature_min_shift9_average4',\n",
    " 'temperature_max_shift2_average7',\n",
    " 'temperature_max_shift3_average2',\n",
    " 'cloud_cover_min_shift10_average2',\n",
    " 'cloud_cover_max_shift3_average7',\n",
    " 'humidity_avg_shift1_average3',\n",
    " 'humidity_avg_shift2_average6',\n",
    " 'humidity_avg_shift6_average10',\n",
    " 'humidity_min_shift9_average3',\n",
    " 'humidity_max_shift6_average7',\n",
    " 'humidity_max_shift8_average5',\n",
    " 'precipitation_probability_avg_shift8_average7',\n",
    " 'precipitation_probability_min_shift1_average7',\n",
    " 'precipitation_probability_min_shift4_average9',\n",
    " 'precipitation_probability_max_shift1_average3',\n",
    " 'precipitation_probability_max_shift2_average7',\n",
    " 'precipitation_probability_max_shift7_average5',\n",
    " 'precipitation_probability_max_shift10_average2',\n",
    " 'precipitation_intensity_min_shift9_average6',\n",
    " 'precipitation_intensity_avg_shift-1',\n",
    " 'precipitation_probability_max_shift-1',\n",
    " 'precipitation_intensity_max_shift-1',\n",
    " 'precipitation_intensity_avg_shift-2',\n",
    " # manually added\n",
    " 'precipitation_intensity_avg_shift-3',\n",
    " 'precipitation_intensity_avg_shift-4',\n",
    " 'precipitation_intensity_avg_shift-5',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions\n",
    "def weather_forecast(X_train):\n",
    "    postfixes = ['avg', 'min', 'max']\n",
    "    for i in range(1,6):\n",
    "        for postfix in postfixes:\n",
    "            X_train[f\"precipitation_probability_{postfix}_shift-{i}\"] = X_train[f'precipitation_probability_{postfix}'].shift(-i)\n",
    "            X_train[f\"precipitation_intensity_{postfix}_shift-{i}\"] = X_train[f'precipitation_intensity_{postfix}'].shift(-i)\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aquifer in aquifers_list:\n",
    "    aquifer_by_stations[aquifer] = weather_forecast(aquifer_by_stations[aquifer])\n",
    "    aquifer_by_stations[aquifer] = aquifer_by_stations[aquifer][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "model = LinearRegression(n_jobs=-1)\n",
    "\n",
    "horizon_max = 5\n",
    "day_len = 365\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon_max)]\n",
    "\n",
    "# Dictionary for storing the predictions for all of the stations\n",
    "predictions_by_stations = {key: [] for key in aquifers_list}\n",
    "\n",
    "for aquifer in aquifers_list:\n",
    "    predictions = []\n",
    "\n",
    "    for horizon in range (1, horizon_max+1, 1):\n",
    "        # Define the train and test set\n",
    "        X_train = aquifer_by_stations[aquifer][best_features][:-(day_len + horizon)]\n",
    "        y_train = aquifer_by_stations[aquifer][features_target][horizon:-day_len]\n",
    "\n",
    "        X_test = aquifer_by_stations[aquifer][best_features][-(day_len + horizon):-horizon]\n",
    "        y_test = aquifer_by_stations[aquifer][features_target][-day_len:]\n",
    "        \n",
    "        # Scale the features\n",
    "        for column in X_test.columns:\n",
    "            X_test[column] = standard_scaling_transform(X_train[column], X_test[column])\n",
    "            X_train[column] = standard_scaling(X_train[column])\n",
    "        \n",
    "        y_train = standard_scaling(y_train)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = model.predict(X_test).tolist()\n",
    "        # Flatten\n",
    "        forecast = np.ravel(forecast)\n",
    "\n",
    "        # Unscale the predictions\n",
    "        forecast = standard_unscaling(aquifer_by_stations[aquifer]['altitude_diff'][horizon:-day_len], forecast)\n",
    "\n",
    "        # Store to the predictions\n",
    "        predictions.append(forecast)\n",
    "        \n",
    "        # Calculate and save the r2 score\n",
    "        r2_scores[horizon-1].append(r2_score(y_test, forecast))\n",
    "\n",
    "    # Store the predictions to the dictionary\n",
    "    predictions_by_stations[aquifer] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['altitude_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[4][-200:], color=\"tomato\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[2][-200:], color=\"green\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions[4][-200:], color=\"grey\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['precipitation_probability_max'][-200:].apply(lambda x: x/20), color=\"brown\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['precipitation'][-200:].apply(lambda x: x/130), color=\"olive\", label=\"forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], predictions_by_stations[85064][0][-200:], color=\"grey\", label=\"forecast\")\n",
    "#plt.savefig('../data/interim/plot.svg', format='svg')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/linear-regression/linear-regression-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/linear-regression/linear-regression-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/linear-regression/linear-regression-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary with predictions\n",
    "joblib.dump(predictions_by_stations, '../reports/linear-regression/linear-regression-ground-water-predictions.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
