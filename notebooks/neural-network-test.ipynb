{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing various NN's on time series**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-BEATS, PatchTST\n",
    "from neuralforecast.models import NBEATS, PatchTST\n",
    "from neuralforecast.losses.pytorch import HuberLoss\n",
    "from neuralforecast.core import NeuralForecast\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Hyperparameter tuning\n",
    "import optuna\n",
    "\n",
    "# N-HiTS\n",
    "from darts import TimeSeries\n",
    "from darts.models import NHiTSModel\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "# DeepAR\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.torch.model.deepar import DeepAREstimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaling(x):\n",
    "    mean = np.mean(np.abs(x))\n",
    "    s = np.std(x)\n",
    "\n",
    "    return (x - mean)/s\n",
    "\n",
    "def standard_unscaling(original, scaled):\n",
    "    mean = np.mean(np.abs(original))\n",
    "    s = np.std(original)\n",
    "\n",
    "    return (scaled * s) + mean\n",
    "\n",
    "# Scaler, that scales data according to other data\n",
    "def standard_scaling_transform(original, to_scale):\n",
    "    mean = np.mean(np.abs(original))\n",
    "    s = np.std(original)\n",
    "\n",
    "    return (to_scale - mean)/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1** N-BEATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.1** Aquifer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "aquifer_by_stations = joblib.load('aquifer_by_stations.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = aquifer_by_stations[1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = Y_df.rename(columns={'date':'ds', 'altitude_diff':'y', 'station_id':'unique_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = Y_df[['ds', 'y', 'unique_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 12\n",
    "val_size = 12\n",
    "test_size = 12\n",
    "\n",
    "nbeats = NBEATS(h=horizon, input_size=3*horizon, loss=HuberLoss(), devices=1, accelerator='cuda')\n",
    "\n",
    "nf = NeuralForecast(models=[nbeats], freq='D')\n",
    "nbeats_forecasts_df = nf.cross_validation(df=Y_df[:-12], val_size=val_size, test_size=test_size, n_windows=None, verbose=True)\n",
    "\n",
    "\n",
    "nbeats_forecasts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbeats_forecasts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbeats_forecasts_df.iloc[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(Y_df['ds'][-200:], Y_df['y'][-200:], color='royalblue', label='true data')\n",
    "plt.plot(Y_df['ds'][-12:], nbeats_forecasts_df['NBEATS'].iloc[:12], color='tomato', label='prediction')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last 5 days\n",
    "# This is done to enable direct comparison to the randomforest,\n",
    "# there the 5 days are removed because of the weather forecast generation\n",
    "for aquifer in aquifers_list:\n",
    "    aquifer_by_stations[aquifer] = aquifer_by_stations[aquifer][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''{'input_size': 15,\n",
    " 'n_harmonics': 5,\n",
    " 'n_polynomials': 5,\n",
    " 'scaler_type': 'robust',\n",
    " 'learning_rate': 0.001,\n",
    " 'max_steps': 25,\n",
    " 'val_size': 10,\n",
    " 'n_blocks_season': 3,\n",
    " 'n_blocks_trend': 3,\n",
    " 'n_blocks_ident': 1,\n",
    " 'mlp_units': 128,\n",
    " 'num_hidden': 1}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 5 # prediction horizon\n",
    "day_len = 365 # number of days to forecast\n",
    "val_size = 2*horizon\n",
    "\n",
    "models = [NBEATS(h=horizon, \n",
    "                 loss=HuberLoss(),\n",
    "                 accelerator='cuda',\n",
    "                 input_size=3*horizon,\n",
    "                 n_harmonics=5,\n",
    "                 n_polynomials=5,\n",
    "                 scaler_type='robust',\n",
    "                 learning_rate=0.001,\n",
    "                 max_steps=25,\n",
    "                 n_blocks=[3, 3, 1],\n",
    "                 mlp_units=[[128, 128]],\n",
    "                 devices=[0],\n",
    "                 logger=False)]\n",
    "\n",
    "model = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon)]\n",
    "\n",
    "# Dictionary for storing the predictions\n",
    "predictions_by_stations = {key: [] for key in aquifer_by_stations}\n",
    "\n",
    "for aquifer in aquifers_list:\n",
    "    # List for storing the predictions\n",
    "    predictions = [[] for _ in range(5)]\n",
    "\n",
    "    # Get the dataset for the aquifer\n",
    "    y = aquifer_by_stations[aquifer]\n",
    "\n",
    "    # Rename the columns (library wants to have specific names)\n",
    "    y = y.rename(columns={'date':'ds', 'altitude_diff':'y', 'station_id':'unique_id'})\n",
    "\n",
    "    # Only keep these 3 columns\n",
    "    y = y[['ds', 'y', 'unique_id']]\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(y[:-day_len], val_size=val_size)\n",
    "\n",
    "    # Iterate from day_len days before the end, to the last day\n",
    "    for i in range(day_len + (horizon-1), 0, -1):\n",
    "        \n",
    "        # Predict\n",
    "        forecast = model.predict(df=y[:-i], verbose=0)\n",
    "\n",
    "        # Store the results for every prediction horizon separately\n",
    "        for i in range(horizon):\n",
    "            predictions[i].append(forecast['NBEATS'].values[i])\n",
    "    \n",
    "    # Clean up the results\n",
    "    predictions[0] = predictions[0][-365:]\n",
    "    predictions[1] = predictions[1][3:-1]\n",
    "    predictions[2] = predictions[2][2:-2]\n",
    "    predictions[3] = predictions[3][1:-3]\n",
    "    predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "    # Store the predictions to the dictionary\n",
    "    predictions_by_stations[aquifer] = predictions\n",
    "\n",
    "    # Calculate the r2 scores and store them in a list\n",
    "    for i in range(horizon):\n",
    "        r2_scores[i].append(r2_score(aquifer_by_stations[aquifer]['altitude_diff'][-day_len:], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['altitude_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-day_len:], predictions[2], color=\"tomato\", label=\"forecast\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-day_len:], predictions_by_stations[85064][2], color=\"tomato\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/n-beats/n-beats-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/n-beats/n-beats-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/n-beats/n-beats-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary with predictions\n",
    "joblib.dump(predictions_by_stations, '../reports/n-beats/n-beats-ground-water-predictions.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick test #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 5\n",
    "\n",
    "train = aquifer_by_stations[1010][:-h]\n",
    "train = train.rename(columns={'date':'ds', 'altitude_diff':'y', 'station_id':'unique_id'})\n",
    "train = train[['ds', 'y', 'unique_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS \n",
    "from neuralforecast.losses.pytorch import DistributionLoss\n",
    "\n",
    "models = [NBEATS(h=h,input_size=3*h,\n",
    "                 loss=HuberLoss(),\n",
    "                 max_steps=200,\n",
    "                 scaler_type='standard',\n",
    "                 accelerator='cuda')]\n",
    "\n",
    "\n",
    "model = NeuralForecast(models=models, freq='D')\n",
    "model.fit(train, val_size=h)\n",
    "\n",
    "\n",
    "p =  model.predict(train)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[1010]['date'][-20:], aquifer_by_stations[1010]['altitude_diff'][-20:], color='royalblue', label='true data')\n",
    "plt.plot(p['ds'].iloc[:h], p['NBEATS'].iloc[:h], color='tomato', label='prediction')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sub>We do hyperparameter tuning by choosing 4 stations from the ones we are going to test. We leave the last 200 days for testing. We use the last 100 days of the remaining dataset for the validation. On the validation we test the parameters</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon and the day_len\n",
    "horizon = 5\n",
    "day_len = 100\n",
    "test_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    input_size = trial.suggest_categorical('input_size', [horizon, 2*horizon, 3* horizon, 4*horizon])\n",
    "    \n",
    "    n_harmonics = trial.suggest_int('n_harmonics', 1, 5)\n",
    "    n_polynomials = trial.suggest_int('n_polynomials', 1, 5)\n",
    "    \n",
    "    scaler_type = trial.suggest_categorical('scaler_type', ['standard', 'robust'])\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [1e-5, 1e-4, 1e-3, 1e-2, 1e-1])\n",
    "\n",
    "    max_steps = trial.suggest_categorical('max_steps', [10, 25, 50, 10, 200])\n",
    "\n",
    "    validation_size = trial.suggest_categorical('val_size', [horizon, 2*horizon, 3*horizon])\n",
    "\n",
    "    n_blocks_season = trial.suggest_int('n_blocks_season', 1, 3)\n",
    "    n_blocks_trend = trial.suggest_int('n_blocks_trend', 1, 3)\n",
    "    n_blocks_identity = trial.suggest_int('n_blocks_ident', 1, 3)\n",
    "    \n",
    "    mlp_units_n = trial.suggest_categorical('mlp_units', [32, 64, 128, 256, 512])\n",
    "    num_hidden = trial.suggest_int('num_hidden', 1, 3)\n",
    "    \n",
    "    n_blocks = [n_blocks_season, n_blocks_trend, n_blocks_identity]\n",
    "    mlp_units=[[mlp_units_n, mlp_units_n]]*num_hidden\n",
    "\n",
    "    models = [NBEATS(h=horizon,input_size=input_size,\n",
    "                 loss=HuberLoss(),\n",
    "                 max_steps=max_steps,\n",
    "                 learning_rate=learning_rate,\n",
    "                 n_harmonics=n_harmonics,\n",
    "                 n_polynomials=n_polynomials,\n",
    "                 scaler_type=scaler_type,\n",
    "                 mlp_units=mlp_units,\n",
    "                 n_blocks=n_blocks,\n",
    "                 accelerator='cuda',\n",
    "                 logger=False)\n",
    "                 ]\n",
    "    model = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon)]\n",
    "    \n",
    "    for aquifer in aquifers_list:\n",
    "        # List for storing the predictions\n",
    "        predictions = [[] for _ in range(5)]\n",
    "\n",
    "        # Get the dataset for the aquifer\n",
    "        y = aquifer_by_stations[aquifer][:-test_len]\n",
    "\n",
    "        # Rename the columns (library wants to have specific names)\n",
    "        y = y.rename(columns={'date':'ds', 'altitude_diff':'y', 'station_id':'unique_id'})\n",
    "\n",
    "        # Only keep these 3 columns\n",
    "        y = y[['ds', 'y', 'unique_id']]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(y[:-day_len], val_size=validation_size)\n",
    "\n",
    "        # Iterate from day_len days before the end, to the last day\n",
    "        for i in range(day_len + (horizon-1), 0, -1):\n",
    "            \n",
    "            # Predict\n",
    "            forecast = model.predict(df=y[:-i], verbose=0)\n",
    "\n",
    "            # Store the results for every prediction horizon separately\n",
    "            for i in range(horizon):\n",
    "                predictions[i].append(forecast['NBEATS'].values[i])\n",
    "        \n",
    "        # Clean up the results\n",
    "        predictions[0] = predictions[0][-day_len:]\n",
    "        predictions[1] = predictions[1][3:-1]\n",
    "        predictions[2] = predictions[2][2:-2]\n",
    "        predictions[3] = predictions[3][1:-3]\n",
    "        predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "        # Calculate the r2 scores and store them in a list\n",
    "        for i in range(horizon):\n",
    "            r2_scores[i].append(r2_score(y['y'][-day_len:], predictions[i]))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    print(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.2** Surface water data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "watercourse_by_stations = joblib.load('../data/interim/watercourse_by_stations.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparemeter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon and the day_len\n",
    "horizon = 5\n",
    "day_len = 100\n",
    "test_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = [4270, 4570, 4515, 6068]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    input_size = trial.suggest_categorical('input_size', [horizon, 2*horizon, 3* horizon, 4*horizon])\n",
    "    \n",
    "    n_harmonics = trial.suggest_int('n_harmonics', 1, 5)\n",
    "    n_polynomials = trial.suggest_int('n_polynomials', 1, 5)\n",
    "    \n",
    "    scaler_type = trial.suggest_categorical('scaler_type', ['standard', 'robust'])\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [1e-5, 1e-4, 1e-3, 1e-2, 1e-1])\n",
    "\n",
    "    max_steps = trial.suggest_categorical('max_steps', [10, 25, 50, 10, 200])\n",
    "\n",
    "    validation_size = trial.suggest_categorical('val_size', [horizon, 2*horizon, 3*horizon])\n",
    "\n",
    "    n_blocks_season = trial.suggest_int('n_blocks_season', 1, 3)\n",
    "    n_blocks_trend = trial.suggest_int('n_blocks_trend', 1, 3)\n",
    "    n_blocks_identity = trial.suggest_int('n_blocks_ident', 1, 3)\n",
    "    \n",
    "    mlp_units_n = trial.suggest_categorical('mlp_units', [32, 64, 128, 256, 512])\n",
    "    num_hidden = trial.suggest_int('num_hidden', 1, 3)\n",
    "    \n",
    "    n_blocks = [n_blocks_season, n_blocks_trend, n_blocks_identity]\n",
    "    mlp_units=[[mlp_units_n, mlp_units_n]]*num_hidden\n",
    "\n",
    "    models = [NBEATS(h=horizon,input_size=input_size,\n",
    "                 loss=HuberLoss(),\n",
    "                 max_steps=max_steps,\n",
    "                 learning_rate=learning_rate,\n",
    "                 n_harmonics=n_harmonics,\n",
    "                 n_polynomials=n_polynomials,\n",
    "                 scaler_type=scaler_type,\n",
    "                 mlp_units=mlp_units,\n",
    "                 n_blocks=n_blocks,\n",
    "                 accelerator='cuda',\n",
    "                 logger=False)\n",
    "                 ]\n",
    "    model = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon)]\n",
    "    \n",
    "    for station in station_list:\n",
    "        # List for storing the predictions\n",
    "        predictions = [[] for _ in range(5)]\n",
    "\n",
    "        # Get the dataset for the aquifer\n",
    "        y = watercourse_by_stations[station][:-test_len]\n",
    "\n",
    "        # Rename the columns (library wants to have specific names)\n",
    "        y = y.rename(columns={'date':'ds', 'level_diff':'y', 'station_id':'unique_id'})\n",
    "\n",
    "        # Only keep these 3 columns\n",
    "        y = y[['ds', 'y', 'unique_id']]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(y[:-day_len], val_size=validation_size)\n",
    "\n",
    "        # Iterate from day_len days before the end, to the last day\n",
    "        for i in range(day_len + (horizon-1), 0, -1):\n",
    "            \n",
    "            # Predict\n",
    "            forecast = model.predict(df=y[:-i], verbose=0)\n",
    "\n",
    "            # Store the results for every prediction horizon separately\n",
    "            for i in range(horizon):\n",
    "                predictions[i].append(forecast['NBEATS'].values[i])\n",
    "        \n",
    "        # Clean up the results\n",
    "        predictions[0] = predictions[0][-day_len:]\n",
    "        predictions[1] = predictions[1][3:-1]\n",
    "        predictions[2] = predictions[2][2:-2]\n",
    "        predictions[3] = predictions[3][1:-3]\n",
    "        predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "        # Calculate the r2 scores and store them in a list\n",
    "        for i in range(horizon):\n",
    "            r2_scores[i].append(r2_score(y['y'][-day_len:], predictions[i]))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    print(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of station used for testing\n",
    "station_list = ['2530', '2620', '4200', '4230', '4270', '4515', '4520', '4570', '4575', '5040', '5078', '5330', '5425', '5500', '6060', '6068', '6200', '6220', '6300', '6340', '8454', '8565']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the stations to int\n",
    "for i in range(len(station_list)):\n",
    "    station_list[i] = int(station_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''{'input_size': 10,\n",
    " 'n_harmonics': 2,\n",
    " 'n_polynomials': 4,\n",
    " 'scaler_type': 'robust',\n",
    " 'learning_rate': 0.01,\n",
    " 'max_steps': 50,\n",
    " 'val_size': 10,\n",
    " 'n_blocks_season': 1,\n",
    " 'n_blocks_trend': 1,\n",
    " 'n_blocks_ident': 3,\n",
    " 'mlp_units': 32,\n",
    " 'num_hidden': 2}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 5 # prediction horizon\n",
    "day_len = 200 # number of days to forecast\n",
    "val_size = 2*horizon\n",
    "\n",
    "models = [NBEATS(h=horizon, \n",
    "                 loss=HuberLoss(),\n",
    "                 accelerator='cuda',\n",
    "                 input_size=2*horizon,\n",
    "                 n_harmonics=2,\n",
    "                 n_polynomials=4,\n",
    "                 scaler_type='robust',\n",
    "                 learning_rate=0.01,\n",
    "                 max_steps=50,\n",
    "                 n_blocks=[1, 1, 3],\n",
    "                 mlp_units=[[32, 32], [32, 32]],\n",
    "                 logger=False)]\n",
    "\n",
    "model = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon)]\n",
    "\n",
    "for station in station_list:\n",
    "    # List for storing the predictions\n",
    "    predictions = [[] for _ in range(5)]\n",
    "\n",
    "    # Get the dataset for the aquifer\n",
    "    y = watercourse_by_stations[station]\n",
    "\n",
    "    # Rename the columns (library wants to have specific names)\n",
    "    y = y.rename(columns={'date':'ds', 'level_diff':'y', 'station_id':'unique_id'})\n",
    "\n",
    "    # Only keep these 3 columns\n",
    "    y = y[['ds', 'y', 'unique_id']]\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(y[:-day_len], val_size=horizon)\n",
    "\n",
    "    # Iterate from day_len days before the end, to the last day\n",
    "    for i in range(day_len + (horizon-1), 0, -1):\n",
    "        \n",
    "        # Predict\n",
    "        forecast = model.predict(df=y[:-i], verbose=0)\n",
    "\n",
    "        # Store the results for every prediction horizon separately\n",
    "        for i in range(horizon):\n",
    "            predictions[i].append(forecast['NBEATS'].values[i])\n",
    "    \n",
    "    # Clean up the results\n",
    "    predictions[0] = predictions[0][-200:]\n",
    "    predictions[1] = predictions[1][3:-1]\n",
    "    predictions[2] = predictions[2][2:-2]\n",
    "    predictions[3] = predictions[3][1:-3]\n",
    "    predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "    # Calculate the r2 scores and store them in a list\n",
    "    for i in range(horizon):\n",
    "        r2_scores[i].append(r2_score(watercourse_by_stations[station]['level_diff'][-day_len:], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(watercourse_by_stations[station]['date'][-200:], watercourse_by_stations[station]['altitude_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(watercourse_by_stations[station]['date'][-day_len:], predictions[0], color=\"tomato\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/n-beats/n-beats-surface-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/n-beats/n-beats-surface-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(station_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/n-beats/n-beats-surface-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2** N-HiTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install darts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1** Aquifer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the variable target as altitude_diff\n",
    "data = aquifer_by_stations[1010][:-horizon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is a pandas DataFrame with a datetime index and one or more columns\n",
    "target = TimeSeries.from_dataframe(data, time_col='date', value_cols='altitude_diff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model parameters\n",
    "model = NHiTSModel(\n",
    "    input_chunk_length=6,\n",
    "    output_chunk_length=6,\n",
    "    num_blocks=2,\n",
    "    n_epochs=50\n",
    "    #pl_trainer_kwargs={'logger': False, \"accelerator\": \"gpu\", \"devices\": [0]}\n",
    ")\n",
    "# Fit the model\n",
    "model.fit(target) #, pl_trainer_kwargs={'logger': False, \"accelerator\": \"gpu\", \"devices\": [0]})\n",
    "\n",
    "# Make predictions\n",
    "pred = model.predict(horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.values()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for value in pred.values():\n",
    "    predictions.append(value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the result\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[1010]['date'][-200:], aquifer_by_stations[1010]['altitude_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(aquifer_by_stations[1010]['date'][-horizon:], predictions, color=\"tomato\", label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon, day_len (number of predicted days), test_len (number of days used for final testing)\n",
    "horizon = 5\n",
    "day_len = 100\n",
    "test_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations to test\n",
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    input_chunk_length = trial.suggest_int('input_chunk_length', 5, 70)\n",
    "    output_chunk_length = trial.suggest_int('output_chunk_length', 1, 10)\n",
    "    num_stacks = trial.suggest_int('num_stacks', 1, 4)\n",
    "    num_blocks = trial.suggest_int('num_blocks', 1, 3)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 5)\n",
    "    layer_widths = trial.suggest_categorical('layer_widths', [64, 128, 256, 512])\n",
    "    dropout = trial.suggest_categorical('dropout', [0.1, 0.2])\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    n_epochs = trial.suggest_int('n_epochs', 10, 200)\n",
    "\n",
    "    model = NHiTSModel(input_chunk_length=input_chunk_length,\n",
    "                     output_chunk_length=output_chunk_length,\n",
    "                     num_stacks=num_stacks,\n",
    "                     num_blocks=num_blocks,\n",
    "                     num_layers=num_layers,\n",
    "                     layer_widths=layer_widths,\n",
    "                     dropout=dropout,\n",
    "                     optimizer_kwargs={'lr': learning_rate},\n",
    "                     n_epochs=n_epochs,\n",
    "                     pl_trainer_kwargs={'logger': False, \"accelerator\": \"gpu\", \"devices\": [0]})\n",
    "    \n",
    "\n",
    "\n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon)]\n",
    "    \n",
    "    for aquifer in aquifers_list:\n",
    "        # List for storing the predictions\n",
    "        predictions = [[] for _ in range(5)]\n",
    "\n",
    "        # Get the dataset for the aquifer\n",
    "        y = aquifer_by_stations[aquifer][:-test_len]\n",
    "\n",
    "        # Change to TimeSeries format (required by the library)\n",
    "        y = TimeSeries.from_dataframe(y, time_col='date', value_cols='altitude_diff')\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(y[:-day_len])\n",
    "\n",
    "        # Iterate from day_len days before the end, to the last day\n",
    "        for i in range(day_len + (horizon-1), 0, -1):\n",
    "            \n",
    "            # Predict\n",
    "            forecast = model.predict(n=horizon, series=y[:-i])\n",
    "\n",
    "\n",
    "            # Store the results for every prediction horizon separately\n",
    "            for i in range(horizon):\n",
    "                predictions[i].append(forecast.values()[i][0])\n",
    "        \n",
    "        # Clean up the results\n",
    "        predictions[0] = predictions[0][-day_len:]\n",
    "        predictions[1] = predictions[1][3:-1]\n",
    "        predictions[2] = predictions[2][2:-2]\n",
    "        predictions[3] = predictions[3][1:-3]\n",
    "        predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "        # Calculate the r2 scores and store them in a list\n",
    "        for i in range(horizon):\n",
    "            r2_scores[i].append(r2_score(aquifer_by_stations[aquifer]['altitude_diff'][-(day_len+test_len):-test_len], predictions[i]))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    print(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test on multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''{'input_chunk_length': 46,\n",
    " 'output_chunk_length': 8,\n",
    " 'num_stacks': 3,\n",
    " 'num_blocks': 2,\n",
    " 'num_layers': 4,\n",
    " 'layer_widths': 512,\n",
    " 'dropout': 0.2,\n",
    " 'learning_rate': 0.0001,\n",
    " 'n_epochs': 89}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 5 # prediction horizon\n",
    "day_len = 200 # number of days to forecast\n",
    "\n",
    "# Set the model parameters\n",
    "model = NHiTSModel(\n",
    "    input_chunk_length=46,\n",
    "    output_chunk_length=8,\n",
    "    num_blocks=2,\n",
    "    num_stacks=3,\n",
    "    num_layers=4,\n",
    "    layer_widths=512,\n",
    "    dropout=0.2,\n",
    "    n_epochs=89,\n",
    "    optimizer_kwargs={'lr': 1e-4},\n",
    "    pl_trainer_kwargs={'logger': False, \"accelerator\": \"gpu\", \"devices\": [0]}\n",
    ")\n",
    "\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon)]\n",
    "\n",
    "for aquifer in aquifers_list:\n",
    "    # List for storing the predictions\n",
    "    predictions = [[] for _ in range(5)]\n",
    "\n",
    "    # Get the dataset for the aquifer\n",
    "    y = aquifer_by_stations[aquifer]\n",
    "\n",
    "    # Change the format to TimeSeries\n",
    "    y = TimeSeries.from_dataframe(y, time_col='date', value_cols='altitude_diff')\n",
    "    \n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(y[:-day_len])\n",
    "\n",
    "    # Iterate from day_len days before the end, to the last day\n",
    "    for i in range(day_len + (horizon-1), 0, -1):\n",
    "        \n",
    "        # Make predictions\n",
    "        forecast = model.predict(n=horizon, series=y[:-i])\n",
    "\n",
    "        # Store the results for every prediction horizon separately\n",
    "        for i in range(horizon):\n",
    "            predictions[i].append(forecast.values()[i][0])\n",
    "    \n",
    "    # Clean up the results\n",
    "    predictions[0] = predictions[0][-200:]\n",
    "    predictions[1] = predictions[1][3:-1]\n",
    "    predictions[2] = predictions[2][2:-2]\n",
    "    predictions[3] = predictions[3][1:-3]\n",
    "    predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "    # Calculate the r2 scores and store them in a list\n",
    "    for i in range(horizon):\n",
    "        r2_scores[i].append(r2_score(aquifer_by_stations[aquifer]['altitude_diff'][-day_len:], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['altitude_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-day_len:], predictions[3], color=\"tomato\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/n-hits/n-hits-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/n-hits/n-hits-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/n-hits/n-hits-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2** Watercourse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon, day_len (number of predicted days), test_len (number of days used for final testing)\n",
    "horizon = 5\n",
    "day_len = 100\n",
    "test_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations to test\n",
    "station_list = [4270, 4570, 4515, 6068]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    input_chunk_length = trial.suggest_int('input_chunk_length', 5, 70)\n",
    "    output_chunk_length = trial.suggest_int('output_chunk_length', 1, 10)\n",
    "    num_stacks = trial.suggest_int('num_stacks', 1, 4)\n",
    "    num_blocks = trial.suggest_int('num_blocks', 1, 3)\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 5)\n",
    "    layer_widths = trial.suggest_categorical('layer_widths', [64, 128, 256, 512])\n",
    "    dropout = trial.suggest_categorical('dropout', [0.1, 0.2])\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    n_epochs = trial.suggest_int('n_epochs', 10, 200)\n",
    "\n",
    "    model = NHiTSModel(input_chunk_length=input_chunk_length,\n",
    "                     output_chunk_length=output_chunk_length,\n",
    "                     num_stacks=num_stacks,\n",
    "                     num_blocks=num_blocks,\n",
    "                     num_layers=num_layers,\n",
    "                     layer_widths=layer_widths,\n",
    "                     dropout=dropout,\n",
    "                     optimizer_kwargs={'lr': learning_rate},\n",
    "                     n_epochs=n_epochs,\n",
    "                     pl_trainer_kwargs={'logger': False, \"accelerator\": \"gpu\", \"devices\": [0]})\n",
    "    \n",
    "\n",
    "\n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon)]\n",
    "    \n",
    "    for station in station_list:\n",
    "        # List for storing the predictions\n",
    "        predictions = [[] for _ in range(5)]\n",
    "\n",
    "        # Get the dataset for the aquifer\n",
    "        y = watercourse_by_stations[station][:-test_len]\n",
    "\n",
    "        # Change to TimeSeries format (required by the library)\n",
    "        y = TimeSeries.from_dataframe(y, time_col='date', value_cols='level_diff')\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(y[:-day_len])\n",
    "\n",
    "        # Iterate from day_len days before the end, to the last day\n",
    "        for i in range(day_len + (horizon-1), 0, -1):\n",
    "            \n",
    "            # Predict\n",
    "            forecast = model.predict(n=horizon, series=y[:-i])\n",
    "\n",
    "\n",
    "            # Store the results for every prediction horizon separately\n",
    "            for i in range(horizon):\n",
    "                predictions[i].append(forecast.values()[i][0])\n",
    "        \n",
    "        # Clean up the results\n",
    "        predictions[0] = predictions[0][-day_len:]\n",
    "        predictions[1] = predictions[1][3:-1]\n",
    "        predictions[2] = predictions[2][2:-2]\n",
    "        predictions[3] = predictions[3][1:-3]\n",
    "        predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "        # Calculate the r2 scores and store them in a list\n",
    "        for i in range(horizon):\n",
    "            r2_scores[i].append(r2_score(watercourse_by_stations[station]['level_diff'][-(day_len+test_len):-test_len], predictions[i]))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    print(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test on multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of station used for testing\n",
    "station_list = ['2530', '2620', '4200', '4230', '4270', '4515', '4520', '4570', '4575', '5040', '5078', '5330', '5425', '5500', '6060', '6068', '6200', '6220', '6300', '6340', '8454', '8565']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the stations to int\n",
    "for i in range(len(station_list)):\n",
    "    station_list[i] = int(station_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 5 # prediction horizon\n",
    "day_len = 200 # number of days to forecast\n",
    "\n",
    "# Set the model parameters\n",
    "model = NHiTSModel(\n",
    "    input_chunk_length=3*horizon,\n",
    "    output_chunk_length=3*horizon,\n",
    "    num_blocks=2,\n",
    "    n_epochs=50,\n",
    ")\n",
    "\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon)]\n",
    "\n",
    "for station in station_list:\n",
    "    # List for storing the predictions\n",
    "    predictions = [[] for _ in range(5)]\n",
    "\n",
    "    # Get the dataset for the aquifer\n",
    "    y = watercourse_by_stations[station]\n",
    "\n",
    "    # Change the format to TimeSeries\n",
    "    y = TimeSeries.from_dataframe(y, time_col='date', value_cols='level_diff')\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(y[:-day_len])\n",
    "\n",
    "    # Iterate from day_len days before the end, to the last day\n",
    "    for i in range(day_len + (horizon-1), 0, -1):\n",
    "        \n",
    "        # Make predictions\n",
    "        forecast = model.predict(n=horizon, series=y[:-i])\n",
    "\n",
    "        # Store the results for every prediction horizon separately\n",
    "        for i in range(horizon):\n",
    "            predictions[i].append(forecast.values()[i][0])\n",
    "    \n",
    "    # Clean up the results\n",
    "    predictions[0] = predictions[0][-200:]\n",
    "    predictions[1] = predictions[1][3:-1]\n",
    "    predictions[2] = predictions[2][2:-2]\n",
    "    predictions[3] = predictions[3][1:-3]\n",
    "    predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "    # Calculate the r2 scores and store them in a list\n",
    "    for i in range(horizon):\n",
    "        r2_scores[i].append(r2_score(watercourse_by_stations[station]['level_diff'][-day_len:], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(watercourse_by_stations[station]['date'][-200:], watercourse_by_stations[station]['level_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(watercourse_by_stations[station]['date'][-day_len:], predictions[0], color=\"tomato\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/n-hits/n-hits-surface-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/n-hits/n-hits-surface-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(station_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/n-hits/n-hits-surface-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3** PatchTST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1** Aquifer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 10\n",
    "\n",
    "train = aquifer_by_stations[1010][:-h]\n",
    "train = train.rename(columns={'date':'ds', 'altitude_diff':'y', 'station_id':'unique_id'})\n",
    "train = train[['ds', 'y', 'unique_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'input_size': 55,\n",
    " 'encoder_layers': 2,\n",
    " 'n_heads': 2,\n",
    " 'hidden_size': 64,\n",
    " 'linear_hidden_size': 512,\n",
    " 'dropout': 0.2,\n",
    " 'fc_dropout': 0.1,\n",
    " 'head_dropout': 0.1,\n",
    " 'attn_dropout': 0.2,\n",
    " 'patch_len': 2,\n",
    " 'stride': 3,\n",
    " 'revin': True,\n",
    " 'learning_rate': 1,\n",
    " 'max_steps': 1988}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PatchTST(h=h,\n",
    "                 input_size=55,\n",
    "                 encoder_layers=4,\n",
    "                 n_heads=8,\n",
    "                 hidden_size=64,\n",
    "                 linear_hidden_size=512,\n",
    "                 dropout=0.2,\n",
    "                 fc_dropout=0.1,\n",
    "                 head_dropout=0.1,\n",
    "                 attn_dropout=0.2,\n",
    "                 patch_len=32,\n",
    "                 stride=24,\n",
    "                 revin=True,\n",
    "                 learning_rate=1e-1,\n",
    "                 max_steps=1988,\n",
    "                 logger=False)\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models=[model],\n",
    "    freq='D'\n",
    ")\n",
    "nf.fit(df=train, val_size=h)\n",
    "forecasts = nf.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[1010]['date'][-20:], aquifer_by_stations[1010]['altitude_diff'][-20:], color='royalblue', label='true data')\n",
    "plt.plot(forecasts['ds'].iloc[:h], forecasts['PatchTST'].iloc[:h], color='tomato', label='prediction')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon and the day_len\n",
    "horizon = 5\n",
    "day_len = 100\n",
    "test_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    input_size = trial.suggest_int('input_size', 5, 100)\n",
    "    encoder_layers = trial.suggest_int('encoder_layers', 1, 4)\n",
    "    encoder_layers = 2*encoder_layers\n",
    "    n_heads = trial.suggest_int('n_heads', 1, 3)\n",
    "    if n_heads == 3:\n",
    "        n_heads = 4\n",
    "    n_heads = 8*n_heads\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [64, 128, 256])\n",
    "    linear_hidden_size = trial.suggest_categorical('linear_hidden_size', [128, 256, 512])\n",
    "    dropout = trial.suggest_categorical('dropout', [0.1, 0.2])\n",
    "    fc_dropout = trial.suggest_categorical('fc_dropout', [0.1, 0.2])\n",
    "    head_dropout = trial.suggest_categorical('head_dropout', [0.1, 0.2])\n",
    "    attn_dropout = trial.suggest_categorical('attn_dropout', [0.1, 0.2])\n",
    "    patch_len = trial.suggest_int('patch_len', 1, 4)\n",
    "    patch_len = 16*patch_len\n",
    "    stride = trial.suggest_int('stride', 1, 4)\n",
    "    stride = 8*stride\n",
    "    revin = trial.suggest_categorical('revin', [True, False])\n",
    "    learning_rate = trial.suggest_int('learning_rate', 1, 5)\n",
    "    learning_rate = 10**(-learning_rate)\n",
    "    max_steps = trial.suggest_int('max_steps', 100, 2000)\n",
    "\n",
    "    models = [PatchTST(h=horizon,\n",
    "                       input_size=input_size,\n",
    "                       encoder_layers=encoder_layers,\n",
    "                       n_heads=n_heads,\n",
    "                       hidden_size=hidden_size,\n",
    "                       linear_hidden_size=linear_hidden_size,\n",
    "                       dropout=dropout,\n",
    "                       fc_dropout=fc_dropout,\n",
    "                       head_dropout=head_dropout,\n",
    "                       attn_dropout=attn_dropout,\n",
    "                       patch_len=patch_len,\n",
    "                       stride=stride,\n",
    "                       revin=revin,\n",
    "                       learning_rate=learning_rate,\n",
    "                       max_steps=max_steps,\n",
    "                       logger=False)\n",
    "                 ]\n",
    "    model = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon)]\n",
    "    \n",
    "    for aquifer in aquifers_list:\n",
    "        # List for storing the predictions\n",
    "        predictions = [[] for _ in range(5)]\n",
    "\n",
    "        # Get the dataset for the aquifer\n",
    "        y = aquifer_by_stations[aquifer][:-test_len]\n",
    "\n",
    "        # Rename the columns (library wants to have specific names)\n",
    "        y = y.rename(columns={'date':'ds', 'altitude_diff':'y', 'station_id':'unique_id'})\n",
    "\n",
    "        # Only keep these 3 columns\n",
    "        y = y[['ds', 'y', 'unique_id']]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(y[:-day_len])\n",
    "\n",
    "        # Iterate from day_len days before the end, to the last day\n",
    "        for i in range(day_len + (horizon-1), 0, -1):\n",
    "            \n",
    "            # Predict\n",
    "            forecast = model.predict(df=y[:-i])\n",
    "\n",
    "            # Store the results for every prediction horizon separately\n",
    "            for i in range(horizon):\n",
    "                predictions[i].append(forecast['PatchTST'].values[i])\n",
    "        \n",
    "        # Clean up the results\n",
    "        predictions[0] = predictions[0][-day_len:]\n",
    "        predictions[1] = predictions[1][3:-1]\n",
    "        predictions[2] = predictions[2][2:-2]\n",
    "        predictions[3] = predictions[3][1:-3]\n",
    "        predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "        # Calculate the r2 scores and store them in a list\n",
    "        for i in range(horizon):\n",
    "            r2_scores[i].append(r2_score(y['y'][-day_len:], predictions[i]))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "aquifer_by_stations = joblib.load('aquifer_by_stations.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last 5 days\n",
    "# This is done to enable direct comparison to the randomforest,\n",
    "# there the 5 days are removed because of the weather forecast generation\n",
    "for aquifer in aquifers_list:\n",
    "    aquifer_by_stations[aquifer] = aquifer_by_stations[aquifer][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''{'input_size': 71,\n",
    " 'encoder_layers': 6,\n",
    " 'n_heads': 2,\n",
    " 'hidden_size': 64,\n",
    " 'linear_hidden_size': 512,\n",
    " 'dropout': 0.2,\n",
    " 'fc_dropout': 0.1,\n",
    " 'head_dropout': 0.1,\n",
    " 'attn_dropout': 0.2,\n",
    " 'patch_len': 1,\n",
    " 'stride': 1,\n",
    " 'revin': True,\n",
    " 'learning_rate': 3,\n",
    " 'max_steps': 1323}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 5 # prediction horizon\n",
    "day_len = 365 # number of days to forecast\n",
    "val_size = horizon\n",
    "\n",
    "model = PatchTST(h=horizon,\n",
    "                 input_size=71,\n",
    "                 encoder_layers=12,\n",
    "                 n_heads=16,\n",
    "                 hidden_size=64,\n",
    "                 linear_hidden_size=512,\n",
    "                 dropout=0.2,\n",
    "                 fc_dropout=0.1,\n",
    "                 head_dropout=0.1,\n",
    "                 attn_dropout=0.2,\n",
    "                 patch_len=16,\n",
    "                 stride=8,\n",
    "                 revin=True,\n",
    "                 learning_rate=1e-3,\n",
    "                 max_steps=1323,\n",
    "                 logger=False)\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models=[model],\n",
    "    freq='D'\n",
    ")\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon)]\n",
    "\n",
    "# Dictionary for the predictions from all of the different aquifers\n",
    "predictions_by_stations = {key: [] for key in aquifers_list}\n",
    "\n",
    "for aquifer in aquifers_list:\n",
    "    # List for storing the predictions\n",
    "    predictions = [[] for _ in range(5)]\n",
    "\n",
    "    # Get the dataset for the aquifer\n",
    "    y = aquifer_by_stations[aquifer]\n",
    "\n",
    "    # Rename the columns (library wants to have specific names)\n",
    "    y = y.rename(columns={'date':'ds', 'altitude_diff':'y', 'station_id':'unique_id'})\n",
    "\n",
    "    # Only keep these 3 columns\n",
    "    y = y[['ds', 'y', 'unique_id']]\n",
    "    y_train = y[:-day_len]\n",
    "\n",
    "    # Scale the training set\n",
    "    y_train['y'] = standard_scaling(y['y'][:-day_len])\n",
    "\n",
    "    # Fit the model\n",
    "    nf.fit(y_train, val_size=val_size)\n",
    "\n",
    "    # Iterate from day_len days before the end, to the last day\n",
    "    for i in range(day_len + (horizon-1), 0, -1):\n",
    "        \n",
    "        # Scale the testing set\n",
    "        y_test = y[:-i]\n",
    "        y_test['y'] = standard_scaling_transform(original=y['y'][:-day_len], to_scale=y['y'][:-i])\n",
    "\n",
    "        # Predict\n",
    "        forecast = nf.predict(df=y_test)\n",
    "\n",
    "        # Unscale the prediction\n",
    "        forecast['PatchTST'] = standard_unscaling(y['y'][:-day_len], forecast['PatchTST'])\n",
    "\n",
    "        # Store the results for every prediction horizon separately\n",
    "        for i in range(horizon):\n",
    "            predictions[i].append(forecast['PatchTST'].values[i])\n",
    "    \n",
    "    # Clean up the results\n",
    "    predictions[0] = predictions[0][-day_len:]\n",
    "    predictions[1] = predictions[1][3:-1]\n",
    "    predictions[2] = predictions[2][2:-2]\n",
    "    predictions[3] = predictions[3][1:-3]\n",
    "    predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "    # Add the predictions to the dictionary\n",
    "    predictions_by_stations[aquifer] = predictions\n",
    "\n",
    "    # Calculate the r2 scores and store them in a list\n",
    "    for i in range(horizon):\n",
    "        r2_scores[i].append(r2_score(aquifer_by_stations[aquifer]['altitude_diff'][-day_len:], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-day_len:], aquifer_by_stations[aquifer]['altitude_diff'][-day_len:], color=\"royalblue\", label=\"true data\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-day_len:], predictions[2], color=\"tomato\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-day_len:], predictions_by_stations[85064][2], color=\"tomato\", label=\"forecast\")\n",
    "#plt.plot(aquifer_by_stations[aquifer]['date'][-day_len:], y['y'][-day_len:], color=\"tomato\", label=\"forecast\")\n",
    "plt.plot(standard_unscaling(y['y'][:-day_len], y_train['y']))\n",
    "#plt.plot(y['y'][:-day_len])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/patchtst/patchtst-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/patchtst/patchtst-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/patchtst/patchtst-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary with predictions\n",
    "joblib.dump(predictions_by_stations, '../reports/patchtst/patchtst-ground-water-predictions.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2** Watercourse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon and the day_len\n",
    "horizon = 5\n",
    "day_len = 100\n",
    "test_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations to test\n",
    "station_list = [4270, 4570, 4515, 6068]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    input_size = trial.suggest_int('input_size', 5, 100)\n",
    "    encoder_layers = trial.suggest_int('encoder_layers', 1, 4)\n",
    "    encoder_layers = 2*encoder_layers\n",
    "    n_heads = trial.suggest_int('n_heads', 1, 3)\n",
    "    if n_heads == 3:\n",
    "        n_heads = 4\n",
    "    n_heads = 8*n_heads\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [64, 128, 256])\n",
    "    linear_hidden_size = trial.suggest_categorical('linear_hidden_size', [128, 256, 512])\n",
    "    dropout = trial.suggest_categorical('dropout', [0.1, 0.2])\n",
    "    fc_dropout = trial.suggest_categorical('fc_dropout', [0.1, 0.2])\n",
    "    head_dropout = trial.suggest_categorical('head_dropout', [0.1, 0.2])\n",
    "    attn_dropout = trial.suggest_categorical('attn_dropout', [0.1, 0.2])\n",
    "    patch_len = trial.suggest_int('patch_len', 1, 4)\n",
    "    patch_len = 16*patch_len\n",
    "    stride = trial.suggest_int('stride', 1, 4)\n",
    "    stride = 8*stride\n",
    "    revin = trial.suggest_categorical('revin', [True, False])\n",
    "    learning_rate = trial.suggest_int('learning_rate', 1, 5)\n",
    "    learning_rate = 10**(-learning_rate)\n",
    "    max_steps = trial.suggest_int('max_steps', 100, 2000)\n",
    "\n",
    "    models = [PatchTST(h=horizon,\n",
    "                       input_size=input_size,\n",
    "                       encoder_layers=encoder_layers,\n",
    "                       n_heads=n_heads,\n",
    "                       hidden_size=hidden_size,\n",
    "                       linear_hidden_size=linear_hidden_size,\n",
    "                       dropout=dropout,\n",
    "                       fc_dropout=fc_dropout,\n",
    "                       head_dropout=head_dropout,\n",
    "                       attn_dropout=attn_dropout,\n",
    "                       patch_len=patch_len,\n",
    "                       stride=stride,\n",
    "                       revin=revin,\n",
    "                       learning_rate=learning_rate,\n",
    "                       max_steps=max_steps,\n",
    "                       logger=False)\n",
    "                 ]\n",
    "    model = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon)]\n",
    "    \n",
    "    for station in station_list:\n",
    "        # List for storing the predictions\n",
    "        predictions = [[] for _ in range(5)]\n",
    "\n",
    "        # Get the dataset for the aquifer\n",
    "        y = watercourse_by_stations[station][:-test_len]\n",
    "\n",
    "        # Rename the columns (library wants to have specific names)\n",
    "        y = y.rename(columns={'date':'ds', 'level_diff':'y', 'station_id':'unique_id'})\n",
    "\n",
    "        # Only keep these 3 columns\n",
    "        y = y[['ds', 'y', 'unique_id']]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(y[:-day_len])\n",
    "\n",
    "        # Iterate from day_len days before the end, to the last day\n",
    "        for i in range(day_len + (horizon-1), 0, -1):\n",
    "            \n",
    "            # Predict\n",
    "            forecast = model.predict(df=y[:-i])\n",
    "\n",
    "            # Store the results for every prediction horizon separately\n",
    "            for i in range(horizon):\n",
    "                predictions[i].append(forecast['PatchTST'].values[i])\n",
    "        \n",
    "        # Clean up the results\n",
    "        predictions[0] = predictions[0][-day_len:]\n",
    "        predictions[1] = predictions[1][3:-1]\n",
    "        predictions[2] = predictions[2][2:-2]\n",
    "        predictions[3] = predictions[3][1:-3]\n",
    "        predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "        # Calculate the r2 scores and store them in a list\n",
    "        for i in range(horizon):\n",
    "            r2_scores[i].append(r2_score(y['y'][-day_len:], predictions[i]))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing on multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of station used for testing\n",
    "station_list = ['2530', '2620', '4200', '4230', '4270', '4515', '4520', '4570', '4575', '5040', '5078', '5330', '5425', '5500', '6060', '6068', '6200', '6220', '6300', '6340', '8454', '8565']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the stations to int\n",
    "for i in range(len(station_list)):\n",
    "    station_list[i] = int(station_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''{'input_size': 19,\n",
    " 'encoder_layers': 2,\n",
    " 'n_heads': 2,\n",
    " 'hidden_size': 256,\n",
    " 'linear_hidden_size': 256,\n",
    " 'dropout': 0.1,\n",
    " 'fc_dropout': 0.1,\n",
    " 'head_dropout': 0.2,\n",
    " 'attn_dropout': 0.1,\n",
    " 'patch_len': 3,\n",
    " 'stride': 3,\n",
    " 'revin': False,\n",
    " 'learning_rate': 3,\n",
    " 'max_steps': 609}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 5 # prediction horizon\n",
    "day_len = 200 # number of days to forecast\n",
    "\n",
    "model = PatchTST(h=horizon,\n",
    "                 input_size=19,\n",
    "                 encoder_layers=4,\n",
    "                 n_heads=16,\n",
    "                 hidden_size=256,\n",
    "                 linear_hidden_size=256,\n",
    "                 dropout=0.1,\n",
    "                 fc_dropout=0.1,\n",
    "                 head_dropout=0.2,\n",
    "                 attn_dropout=0.1,\n",
    "                 patch_len=48,\n",
    "                 stride=24,\n",
    "                 revin=False,\n",
    "                 learning_rate=1e-3,\n",
    "                 max_steps=609,\n",
    "                 logger=False)\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models=[model],\n",
    "    freq='D'\n",
    ")\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon)]\n",
    "\n",
    "for station in station_list:\n",
    "    # List for storing the predictions\n",
    "    predictions = [[] for _ in range(5)]\n",
    "\n",
    "    # Get the dataset for the aquifer\n",
    "    y = watercourse_by_stations[station]\n",
    "\n",
    "    # Rename the columns (library wants to have specific names)\n",
    "    y = y.rename(columns={'date':'ds', 'level_diff':'y', 'station_id':'unique_id'})\n",
    "\n",
    "    # Only keep these 3 columns\n",
    "    y = y[['ds', 'y', 'unique_id']]\n",
    "\n",
    "    # Fit the model\n",
    "    nf.fit(y[:-day_len])\n",
    "\n",
    "    # Iterate from day_len days before the end, to the last day\n",
    "    for i in range(day_len + (horizon-1), 0, -1):\n",
    "        \n",
    "        # Predict\n",
    "        forecast = nf.predict(df=y[:-i])\n",
    "\n",
    "        # Store the results for every prediction horizon separately\n",
    "        for i in range(horizon):\n",
    "            predictions[i].append(forecast['PatchTST'].values[i])\n",
    "    \n",
    "    # Clean up the results\n",
    "    predictions[0] = predictions[0][-200:]\n",
    "    predictions[1] = predictions[1][3:-1]\n",
    "    predictions[2] = predictions[2][2:-2]\n",
    "    predictions[3] = predictions[3][1:-3]\n",
    "    predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "    # Calculate the r2 scores and store them in a list\n",
    "    for i in range(horizon):\n",
    "        r2_scores[i].append(r2_score(watercourse_by_stations[station]['level_diff'][-day_len:], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(watercourse_by_stations[station]['date'][-200:], watercourse_by_stations[station]['level_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(watercourse_by_stations[station]['date'][-day_len:], predictions[2], color=\"tomato\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/patchtst/patchtst-surface-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/patchtst/patchtst-surface-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(station_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/patchtst/patchtst-surface-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4** DeepAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.1** Ground water data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pytorch-lightning\n",
    "#%pip install gluonts\n",
    "#%pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "aquifer_by_stations = joblib.load('aquifer_by_stations.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifer = aquifer_by_stations[85065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 5\n",
    "\n",
    "train_ds = PandasDataset.from_long_dataframe(aquifer[:-horizon], target='altitude_diff', item_id='station_id', \n",
    "                                       timestamp='date', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DeepAREstimator(freq='D', prediction_length=horizon, num_layers=3, trainer_kwargs={'accelerator': 'gpu', 'max_epochs':30, 'logger': False})\n",
    "\n",
    "predictor = estimator.train(train_ds)\n",
    "\n",
    "pred = list(predictor.predict(train_ds))\n",
    "\n",
    "prediction = pred[0].samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer['date'][-170:], aquifer['altitude_diff'][-170:], color=\"royalblue\", label=\"True data\")\n",
    "plt.plot(aquifer['date'][-horizon:], prediction, color=\"tomato\", label=\"Prediction\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the horizon, day_len (number of predicted days), test_len (number of days used for final testing)\n",
    "horizon = 5\n",
    "day_len = 100\n",
    "test_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations to test\n",
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which contains parameters to tune and the model\n",
    "\n",
    "def objective(trial):\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 4)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 20, 200)\n",
    "    context_length = trial.suggest_int('context_length', 5, 20)\n",
    "    lr = trial.suggest_int('lr', 1, 5)\n",
    "    lr = 10**(-lr)\n",
    "    weight_decay = trial.suggest_int('weight_decay', 7, 9)\n",
    "    weight_decay = 10**(-weight_decay)\n",
    "    dropout_rate = trial.suggest_int('dropout_rate', 1, 3)\n",
    "    dropout_rate = dropout_rate*(1e-1)\n",
    "    max_epochs = trial.suggest_int('max_epochs', 10, 100)\n",
    "\n",
    "    model = DeepAREstimator(prediction_length=horizon,\n",
    "                     freq='D',\n",
    "                     trainer_kwargs={'accelerator': 'gpu', 'max_epochs': max_epochs, 'logger': False},\n",
    "                     num_layers=num_layers,\n",
    "                     hidden_size=hidden_size,\n",
    "                     context_length=context_length,\n",
    "                     lr=lr,\n",
    "                     weight_decay=weight_decay,\n",
    "                     dropout_rate=dropout_rate)\n",
    "    \n",
    "\n",
    "    # List for r2 results for different prediction horizons\n",
    "    r2_scores = [[] for _ in range(horizon)]\n",
    "    \n",
    "    for aquifer in aquifers_list:\n",
    "        # List for storing the predictions\n",
    "        predictions = [[] for _ in range(5)]\n",
    "\n",
    "        # Get the dataset for the aquifer\n",
    "        y = aquifer_by_stations[aquifer][:-test_len]\n",
    "\n",
    "        # Change to TimeSeries format (required by the library)\n",
    "        y_temp = PandasDataset.from_long_dataframe(y[:-day_len], target='altitude_diff', item_id='station_id', \n",
    "                                                timestamp='date', freq='D')\n",
    "\n",
    "        # Fit the model\n",
    "        predictor = model.train(y_temp)\n",
    "\n",
    "        # Iterate from day_len days before the end, to the last day\n",
    "        for i in range(day_len + (horizon-1), 0, -1):\n",
    "            \n",
    "            y_temp = PandasDataset.from_long_dataframe(y[:-i], target='altitude_diff', item_id='station_id', \n",
    "                                                            timestamp='date', freq='D')\n",
    "            \n",
    "            # Predict\n",
    "            forecast = list(predictor.predict(y_temp))\n",
    "            \n",
    "            forecast = forecast[0].samples.mean(axis=0)\n",
    "\n",
    "\n",
    "            # Store the results for every prediction horizon separately\n",
    "            for i in range(horizon):\n",
    "                predictions[i].append(forecast[i])\n",
    "        \n",
    "        # Clean up the results\n",
    "        predictions[0] = predictions[0][-day_len:]\n",
    "        predictions[1] = predictions[1][3:-1]\n",
    "        predictions[2] = predictions[2][2:-2]\n",
    "        predictions[3] = predictions[3][1:-3]\n",
    "        predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "        # Calculate the r2 scores and store them in a list\n",
    "        for i in range(horizon):\n",
    "            r2_scores[i].append(r2_score(aquifer_by_stations[aquifer]['altitude_diff'][-(day_len+test_len):-test_len], predictions[i]))\n",
    "    \n",
    "    # Calculate the average r2 score\n",
    "    r2_average =  []\n",
    "    \n",
    "    for i in range(5):\n",
    "        r2_average.append(np.mean(r2_scores[i]))\n",
    "\n",
    "    # Set the loss as average of average r2 scores for different prediction horizons\n",
    "    loss = np.mean(r2_average)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing multiple stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aquifers_list = [85065, 85064]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''{'num_layers': 1,\n",
    " 'hidden_size': 158,\n",
    " 'context_length': 15,\n",
    " 'lr': 3,\n",
    " 'weight_decay': 9,\n",
    " 'dropout_rate': 1,\n",
    " 'max_epochs': 14}'''\n",
    "# To Do !!! test the model with these hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 5 # prediction horizon\n",
    "day_len = 365 # number of days to forecast\n",
    "\n",
    "# Set the model parameters\n",
    "model = DeepAREstimator(prediction_length=horizon,\n",
    "                 freq='D',\n",
    "                 trainer_kwargs={'accelerator': 'gpu', 'max_epochs': 14, 'logger': False},\n",
    "                 num_layers=1,\n",
    "                 hidden_size=158,\n",
    "                 context_length=15,\n",
    "                 lr=1e-3,\n",
    "                 weight_decay=9,\n",
    "                 dropout_rate=1)\n",
    "\n",
    "\n",
    "# List for r2 results for different prediction horizons\n",
    "r2_scores = [[] for _ in range(horizon)]\n",
    "\n",
    "for aquifer in aquifers_list:\n",
    "    # List for storing the predictions\n",
    "    predictions = [[] for _ in range(5)]\n",
    "\n",
    "    # Get the dataset for the aquifer\n",
    "    y = aquifer_by_stations[aquifer]\n",
    "\n",
    "    # Change to TimeSeries format (required by the library)\n",
    "    y_temp = PandasDataset.from_long_dataframe(y[:-day_len], target='altitude_diff', item_id='station_id', \n",
    "                                                timestamp='date', freq='D')\n",
    "    # Fit the model\n",
    "    predictor = model.train(y_temp)\n",
    "\n",
    "    # Iterate from day_len days before the end, to the last day\n",
    "    for i in range(day_len + (horizon-1), 0, -1):\n",
    "        \n",
    "        y_temp = PandasDataset.from_long_dataframe(y[:-i], target='altitude_diff', item_id='station_id', \n",
    "                                                        timestamp='date', freq='D')\n",
    "\n",
    "        # Predict\n",
    "        forecast = list(predictor.predict(y_temp))\n",
    "        \n",
    "        forecast = forecast[0].samples.mean(axis=0)\n",
    "\n",
    "        # Store the results for every prediction horizon separately\n",
    "        for i in range(horizon):\n",
    "            predictions[i].append(forecast[i])\n",
    "    \n",
    "    # Clean up the results\n",
    "    predictions[0] = predictions[0][-day_len:]\n",
    "    predictions[1] = predictions[1][3:-1]\n",
    "    predictions[2] = predictions[2][2:-2]\n",
    "    predictions[3] = predictions[3][1:-3]\n",
    "    predictions[4] = predictions[4][0:-4]\n",
    "\n",
    "    # Calculate the r2 scores and store them in a list\n",
    "    for i in range(horizon):\n",
    "        r2_scores[i].append(r2_score(aquifer_by_stations[aquifer]['altitude_diff'][-day_len:], predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average r2 score\n",
    "r2_average =  []\n",
    "std_dev = []\n",
    "\n",
    "for i in range(5):\n",
    "    r2_average.append(np.mean(r2_scores[i]))\n",
    "    std_dev.append(np.std(r2_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-200:], aquifer_by_stations[aquifer]['altitude_diff'][-200:], color=\"royalblue\", label=\"true data\")\n",
    "plt.plot(aquifer_by_stations[aquifer]['date'][-day_len:], predictions[0], color=\"tomato\", label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average r2_scores\n",
    "with open('../reports/n-hits/n-hits-ground-water-r2.txt', 'w') as file:\n",
    "    for item in r2_average:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the standard deviations\n",
    "with open('../reports/n-hits/n-hits-ground-water-std-dev.txt', 'w') as file:\n",
    "    for item in std_dev:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the r2_scores list\n",
    "r2_scores_transposed = [list(x) for x in zip(*r2_scores)]\n",
    "# Pair up the stations with their r2_scores and store them in a dictionary\n",
    "scores = dict(zip(aquifers_list, r2_scores_transposed))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort them by the value in r2_scores[0]\n",
    "scores_sorted = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1][0])}\n",
    "scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the r2_scores\n",
    "joblib.dump(scores_sorted, '../reports/n-hits/n-hits-ground-water-r2-stations.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2** Watercourse data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
